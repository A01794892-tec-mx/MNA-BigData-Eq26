{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Instalando Dependencias"
      ],
      "metadata": {
        "id": "Q0Xv8Tto_22V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pVQjJoM_B5H"
      },
      "source": [
        "Instalando Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "F1Y1pRcivb5z",
        "outputId": "7bc9b54a-6050-4305-f209-41e6c66556a4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0Ô∏è‚É£   Install Java if not available\n",
            "‚úÖ Java is already installed.\n",
            "\n",
            "1Ô∏è‚É£   Download and install Hadoop and Spark\n",
            "‚úÖ https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz was found\n",
            "‚úÖ 2024-05-15 23:07:12 (74.5 MB/s) - ‚Äòspark-3.5.1-bin-hadoop3.tgz‚Äô saved [400446614/400446614]\n",
            "‚úÖ Uncompressed Spark distribution\n",
            "\n",
            "\n",
            "2Ô∏è‚É£   Start Spark engine\n",
            "‚úÖ no org.apache.spark.deploy.master.Master to stop\n",
            "‚úÖ starting org.apache.spark.deploy.master.Master, logging to /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.master.Master-1-4c283c4b9498.out\n",
            "‚úÖ no org.apache.spark.deploy.worker.Worker to stop\n",
            "‚úÖ starting org.apache.spark.deploy.worker.Worker, logging to /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.worker.Worker-1-4c283c4b9498.out\n",
            "\n",
            "3Ô∏è‚É£   Start Master Web UI\n",
            "Search for port number in log file /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.master.Master-1-4c283c4b9498.out\n",
            "‚úÖ Master UI is available at localhost:8081 (attempt nr. 4)\n",
            "Click on the link below to open the Spark Web UI üöÄ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8081, \"/\", \"https://localhost:8081/\", window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4Ô∏è‚É£   Start history server\n",
            "‚úÖ no org.apache.spark.deploy.history.HistoryServer to stop\n",
            "‚úÖ starting org.apache.spark.deploy.history.HistoryServer, logging to /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.history.HistoryServer-1-4c283c4b9498.out\n",
            "Click on the link below to open the Spark History Server Web UI üöÄ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(18080, \"/\", \"https://localhost:18080/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import requests\n",
        "import subprocess\n",
        "import os\n",
        "import re\n",
        "import socket\n",
        "import shutil\n",
        "import time\n",
        "import sys\n",
        "\n",
        "def run(cmd):\n",
        "    # run a shell command\n",
        "    try:\n",
        "        # Run the command and capture stdout and stderr\n",
        "        subprocess_output = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        # Access stdout (stderr redirected to stdout)\n",
        "        stdout_result = subprocess_output.stdout.strip().splitlines()[-1]\n",
        "        # Process the results as needed\n",
        "        print(f'‚úÖ {stdout_result}')\n",
        "        return stdout_result\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # Handle the error if the command returns a non-zero exit code\n",
        "        print(f\"Command failed with return code {e.returncode}\")\n",
        "        print(\"stdout:\", e.stdout)\n",
        "\n",
        "def is_java_installed():\n",
        "    return shutil.which(\"java\")\n",
        "\n",
        "def install_java():\n",
        "    # Uncomment and modify the desired version\n",
        "    # java_version= 'openjdk-11-jre-headless'\n",
        "    # java_version= 'default-jre'\n",
        "    # java_version= 'openjdk-17-jre-headless'\n",
        "    # java_version= 'openjdk-18-jre-headless'\n",
        "    java_version= 'openjdk-19-jre-headless'\n",
        "    os.environ['JAVA_HOME'] = ' /usr/lib/jvm/java-19-openjdk-amd64'\n",
        "    print(f\"Java not found. Installing {java_version} ... (this might take a while)\")\n",
        "    try:\n",
        "        cmd = f\"apt install -y {java_version}\"\n",
        "        subprocess_output = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        stdout_result = subprocess_output.stdout\n",
        "        # Process the results as needed\n",
        "        print(f'‚úÖ Done installing Java {java_version}')\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # Handle the error if the command returns a non-zero exit code\n",
        "        print(f\"Command failed with return code {e.returncode}\")\n",
        "        print(\"stdout:\", e.stdout)\n",
        "\n",
        "print(\"\\n0Ô∏è‚É£   Install Java if not available\")\n",
        "if is_java_installed():\n",
        "    print(\"‚úÖ Java is already installed.\")\n",
        "else:\n",
        "    install_java()\n",
        "\n",
        "print(\"\\n1Ô∏è‚É£   Download and install Hadoop and Spark\")\n",
        "# URL for downloading Hadoop and Spark\n",
        "SPARK_VERSION = \"3.5.1\"\n",
        "HADOOP_SPARK_URL = \"https://dlcdn.apache.org/spark/spark-\" + SPARK_VERSION + \\\n",
        "                   \"/spark-\" + SPARK_VERSION + \"-bin-hadoop3.tgz\"\n",
        "r = requests.head(HADOOP_SPARK_URL)\n",
        "if r.status_code >= 200 and r.status_code < 400:\n",
        "    print(f'‚úÖ {HADOOP_SPARK_URL} was found')\n",
        "else:\n",
        "    SPARK_CDN = \"https://dlcdn.apache.org/spark/\"\n",
        "    print(f'‚ö†Ô∏è {HADOOP_SPARK_URL} was NOT found. \\nCheck for available Spark versions in {SPARK_CDN}')\n",
        "\n",
        "# set some environment variables\n",
        "os.environ['SPARK_HOME'] = os.path.join(os.getcwd(), os.path.splitext(os.path.basename(HADOOP_SPARK_URL))[0])\n",
        "os.environ['PATH'] = ':'.join([os.path.join(os.environ['SPARK_HOME'], 'bin'), os.environ['PATH']])\n",
        "os.environ['PATH'] = ':'.join([os.path.join(os.environ['SPARK_HOME'], 'sbin'), os.environ['PATH']])\n",
        "\n",
        "# download Spark\n",
        "# using --no-clobber option will prevent wget from downloading file if already present\n",
        "# shell command: wget --no-clobber $HADOOP_SPARK_URL\n",
        "cmd = f\"wget --no-clobber {HADOOP_SPARK_URL}\"\n",
        "run(cmd)\n",
        "\n",
        "# uncompress\n",
        "try:\n",
        "    # Run the command and capture stdout and stderr\n",
        "    cmd = \"([ -d $(basename {0}|sed 's/\\.[^.]*$//') ] && echo -n 'Folder already exists') || (tar xzf $(basename {0}) && echo 'Uncompressed Spark distribution')\"\n",
        "    subprocess_output = subprocess.run(cmd.format(HADOOP_SPARK_URL), shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    # Access stdout (stderr redirected to stdout)\n",
        "    stdout_result = subprocess_output.stdout\n",
        "    # Process the results as needed\n",
        "    print(f'‚úÖ {stdout_result}')\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    # Handle the error if the command returns a non-zero exit code\n",
        "    print(f\"Command failed with return code {e.returncode}\")\n",
        "    print(\"stdout:\", e.stdout)\n",
        "\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£   Start Spark engine\")\n",
        "# start master\n",
        "# shell command: $SPARK_HOME/sbin/start-master.sh\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'stop-master.sh')\n",
        "run(cmd)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'start-master.sh')\n",
        "out = run(cmd)\n",
        "\n",
        "# start one worker (first stop it in case it's already running)\n",
        "# shell command: $SPARK_HOME/sbin/start-worker.sh spark://${HOSTNAME}:7077\n",
        "cmd = [os.path.join(os.environ['SPARK_HOME'], 'sbin', 'stop-worker.sh')]\n",
        "run(cmd)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'start-worker.sh') + ' ' + 'spark://'+socket.gethostname()+':7077'\n",
        "run(cmd)\n",
        "\n",
        "print(\"\\n3Ô∏è‚É£   Start Master Web UI\")\n",
        "# get master UI's port number\n",
        "# the subprocess that's starting the master with start-master.sh\n",
        "# might still not be ready with assigning the port number at this point\n",
        "# therefore we check the logfile a few times (attempts=5) to see if the port\n",
        "# has been assigned. This might take 1-2 seconds.\n",
        "\n",
        "master_log = out.partition(\"logging to\")[2].strip()\n",
        "print(\"Search for port number in log file {}\".format(master_log))\n",
        "attempts = 10\n",
        "search_pattern = \"Successfully started service 'MasterUI' on port (\\d+)\"\n",
        "found = False\n",
        "for i in range(attempts):\n",
        "  if not found:\n",
        "   with open(master_log) as log:\n",
        "      found = re.search(search_pattern, log.read())\n",
        "      if found:\n",
        "          webUIport = found.group(1)\n",
        "          print(f\"‚úÖ Master UI is available at localhost:{webUIport} (attempt nr. {i})\")\n",
        "          break\n",
        "      else:\n",
        "          time.sleep(2) # need to try until port information is found in the logfile\n",
        "          i+=1\n",
        "if not found:\n",
        "  print(\"Could not find port for Master Web UI\\n\")\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    # serve the Web UI on Colab\n",
        "    print(\"Click on the link below to open the Spark Web UI üöÄ\")\n",
        "    from google.colab import output\n",
        "    output.serve_kernel_port_as_window(webUIport)\n",
        "\n",
        "print(\"\\n4Ô∏è‚É£   Start history server\")\n",
        "# start history server\n",
        "# shell command: mkdir -p /tmp/spark-events\n",
        "# shell command: $SPARK_HOME/sbin/start-history-server.sh\n",
        "spark_events_dir = os.path.join('/tmp', 'spark-events')\n",
        "if not os.path.exists(spark_events_dir):\n",
        "    os.mkdir(spark_events_dir)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'stop-history-server.sh')\n",
        "run(cmd)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'start-history-server.sh')\n",
        "run(cmd)\n",
        "\n",
        "if IN_COLAB:\n",
        "    # serve the History Server\n",
        "    print(\"Click on the link below to open the Spark History Server Web UI üöÄ\")\n",
        "    output.serve_kernel_port_as_window(18080)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l8kmJakDEV_S",
        "outputId": "ffeef858-2e70-463e-f066-423dd7f567a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pD7Wr-eWUHO8",
        "outputId": "8ac8b34e-3b12-4b5c-9b25-cb19607779d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=c2d0b4fdcf75c68dc9e4889253972bfd90718b6d53718e13eb8475fb782024fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocesamiento"
      ],
      "metadata": {
        "id": "WfqD-JjsAzqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9LwSZ4HXFaDx"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as fn\n",
        "import os\n",
        "from pyspark.conf import SparkConf\n",
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bOYEaGu_w97s",
        "outputId": "7354e233-0263-492e-ccb2-e646fa36cf85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: a01794892tecmx\n",
            "Your Kaggle Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Dataset URL: https://www.kaggle.com/datasets/andrewmvd/spotify-playlists\n",
            "Downloading spotify-playlists.zip to ./spotify-playlists\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183M/183M [00:01<00:00, 109MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download(\n",
        "\t\"https://www.kaggle.com/datasets/andrewmvd/spotify-playlists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fUBQu1M3wVml"
      },
      "outputs": [],
      "source": [
        "# Set the Spark master URL and other Spark settings\n",
        "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--master local[*] --executor-memory 4G --num-executors 4 pyspark-shell'\n",
        "conf = SparkConf(loadDefaults=True)\n",
        "conf.setMaster(\"local\").setAppName(\"sptifyApp\")\n",
        "sc = SparkContext(conf=conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6SoVP3M8wbAM"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8DuhicncxH0s"
      },
      "outputs": [],
      "source": [
        "spark.conf.set(\"spark.sql.pivotMaxValues\", 2200000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "fG49foAjxMjD",
        "outputId": "b4e66b35-b529-4ecb-ea0b-3430d1053465"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a0a689d6950>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4c283c4b9498:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>sptifyApp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Limpieza de datos"
      ],
      "metadata": {
        "id": "PiDmEFrkBFYb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fr8ED4XBxerM",
        "outputId": "833f28a7-1082-44c2-9a64-549308bc6639"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(user_id='9cc0cfd4d7d7885102480dd99e7a90d6', artistname='Elvis Costello', trackname='(The Angels Wanna Wear My) Red Shoes', playlistname='HARD ROCK 2010')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df = spark.read.option(\"header\", \"true\").csv(\"spotify-playlists//spotify_dataset.csv\")\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "df = df.toDF(*[col.replace(' ', '').replace('\"', '') for col in df.columns])\n",
        "\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creando dimensiones separadas para playlists, artistas, canciones y usuarios, reconstruyendo la matriz de reproducciones con los indices de dichas dimensiones."
      ],
      "metadata": {
        "id": "XNVXXQgCBMh8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "19w5BaphaqGx",
        "outputId": "96342b4d-06c2-4c6c-e01a-05cb7b114723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(user_id='00055176fea33f6e027cd3302289378b', user_id_index=1), Row(user_id='0007f3dd09c91198371454c608d47f22', user_id_index=2), Row(user_id='000b0f32b5739f052b9d40fcc5c41079', user_id_index=3), Row(user_id='000c11a16c89aa4b14b328080f5954ee', user_id_index=4), Row(user_id='00123e0f544dee3ab006aa7f1e5725a7', user_id_index=5), Row(user_id='00139e9cb50fb309549e1561b476226d', user_id_index=6), Row(user_id='00152c870313100559aad7b097d9c1f5', user_id_index=7), Row(user_id='00154ec9dd1acd4ebfb521629dcb3948', user_id_index=8), Row(user_id='001599a07cb8ef5f114a9fcf4e0e2757', user_id_index=9), Row(user_id='0019363a0d57e94d39988c31eeb8d015', user_id_index=10)]\n",
            "[Row(artistname=' Dolce', artistname_index=1), Row(artistname=' OneVoice', artistname_index=2), Row(artistname='!!!', artistname_index=3), Row(artistname='!!! (Chk Chk Chk)', artistname_index=4), Row(artistname='!!! Chk Chik Chick', artistname_index=5), Row(artistname='!ATTENTION!', artistname_index=6), Row(artistname='!DELADAP', artistname_index=7), Row(artistname='!Dela Dap', artistname_index=8), Row(artistname='!DelaDap', artistname_index=9), Row(artistname='!Distain', artistname_index=10)]\n",
            "[Row(trackname=' \"Cachaito\" L√≥pez Y \"Guajiro\" Mirabal De Buena Vista Social Club Y Manuel \"Galb√°n\" Torralba\"', trackname_index=1), Row(trackname=' 15 Years of Tummy Touch Records in Dub', trackname_index=2), Row(trackname=' Alan Jackson', trackname_index=3), Row(trackname=' Ashley Tisdale', trackname_index=4), Row(trackname=' Ashley Tisdale & Lucas Grabeel\"', trackname_index=5), Row(trackname=' Babi Floyd\"', trackname_index=6), Row(trackname=' Babyface & Whitney Houston\"', trackname_index=7), Row(trackname=' Bert with The Whispering Orchestra\"', trackname_index=8), Row(trackname=' Bill Stepney\"', trackname_index=9), Row(trackname=' Bumblefoot', trackname_index=10)]\n",
            "[Row(playlistname=' ', playlistname_index=1), Row(playlistname='        waves', playlistname_index=2), Row(playlistname='  11', playlistname_index=3), Row(playlistname='  Frida', playlistname_index=4), Row(playlistname='  New tunes 05/11', playlistname_index=5), Row(playlistname=\"  You're the Worst\", playlistname_index=6), Row(playlistname='  joni mitchell       ', playlistname_index=7), Row(playlistname='  julia musica', playlistname_index=8), Row(playlistname=' !!', playlistname_index=9), Row(playlistname=' \"\"Appassionata\"\" - Allegro Assai \"\"', playlistname_index=10)]\n",
            "[Row(user_id_index=6511, artistname_index=15, trackname_index=1, playlistname_index=5707), Row(user_id_index=4852, artistname_index=49030, trackname_index=2, playlistname_index=70282), Row(user_id_index=4213, artistname_index=563, trackname_index=10, playlistname_index=577), Row(user_id_index=11018, artistname_index=54, trackname_index=12, playlistname_index=103765), Row(user_id_index=13724, artistname_index=603, trackname_index=28, playlistname_index=31610), Row(user_id_index=12560, artistname_index=344, trackname_index=40, playlistname_index=678), Row(user_id_index=10774, artistname_index=83640, trackname_index=54, playlistname_index=125146), Row(user_id_index=11031, artistname_index=191689, trackname_index=59, playlistname_index=27230), Row(user_id_index=13194, artistname_index=44720, trackname_index=72, playlistname_index=30108), Row(user_id_index=12626, artistname_index=172581, trackname_index=83, playlistname_index=153063)]\n"
          ]
        }
      ],
      "source": [
        "dims={}\n",
        "\n",
        "def df_dim(df, input_col):\n",
        "    windowSpec = Window.orderBy(input_col)\n",
        "    dims[input_col]=df.select(input_col).distinct().withColumn(f\"{input_col}_index\", fn.row_number().over(windowSpec))\n",
        "\n",
        "for col_name in df.columns:\n",
        "    df_dim(df,col_name)\n",
        "\n",
        "for dim in dims.values():\n",
        "    print(dim.head(10))\n",
        "\n",
        "newdf=df\n",
        "\n",
        "for i in range(0, len(df.columns)):\n",
        "    col_name = df.columns[i]\n",
        "    newdf=newdf.join(dims[col_name].withColumnRenamed(col_name, col_name+'_base'), fn.col(col_name)==fn.col(col_name+'_base')).drop(col_name).drop(col_name+'_base')\n",
        "\n",
        "print(newdf.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matriz de reporducciones seg√∫n el artista y normalizaci√≥n de los datos."
      ],
      "metadata": {
        "id": "rwyEmsfrBjjq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5Q4d3ht_cAhi"
      },
      "outputs": [],
      "source": [
        "counts_df = newdf.groupBy(\"user_id_index\", \"artistname_index\").agg(fn.count(\"*\").alias(\"reproductions\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TETF7Ha-cjqS",
        "outputId": "334ce8db-4960-4692-a0a9-6f5805010879"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(user_id_index=11738, artistname_index=212990, reproductions=24, normalized_reproduction=0.0068759342301943195),\n",
              " Row(user_id_index=1036, artistname_index=152785, reproductions=4, normalized_reproduction=0.0008968609865470852),\n",
              " Row(user_id_index=2695, artistname_index=118440, reproductions=20, normalized_reproduction=0.005680119581464873),\n",
              " Row(user_id_index=7942, artistname_index=45951, reproductions=236, normalized_reproduction=0.07025411061285501),\n",
              " Row(user_id_index=4281, artistname_index=258892, reproductions=3, normalized_reproduction=0.0005979073243647235),\n",
              " Row(user_id_index=6765, artistname_index=81653, reproductions=38, normalized_reproduction=0.011061285500747383),\n",
              " Row(user_id_index=5278, artistname_index=125652, reproductions=42, normalized_reproduction=0.012257100149476832),\n",
              " Row(user_id_index=15667, artistname_index=198257, reproductions=44, normalized_reproduction=0.012855007473841554),\n",
              " Row(user_id_index=5381, artistname_index=91263, reproductions=61, normalized_reproduction=0.017937219730941704),\n",
              " Row(user_id_index=13572, artistname_index=280007, reproductions=52, normalized_reproduction=0.015246636771300448)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "max_reproduction = counts_df.agg({\"reproductions\": \"max\"}).collect()[0][0]\n",
        "min_reproduction = counts_df.agg({\"reproductions\": \"min\"}).collect()[0][0]\n",
        "\n",
        "normalized_pl_counts_df = counts_df.withColumn(\"normalized_reproduction\", (fn.col(\"reproductions\") - min_reproduction) / (max_reproduction - min_reproduction))\n",
        "normalized_pl_counts_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sistema de recomendaci√≥n de artistas"
      ],
      "metadata": {
        "id": "MAQ7HvgfAHab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yuERLouodI2i",
        "outputId": "42e61e9a-2087-42fb-b6ea-284498582c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) = 0.12709003382739936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(user_id_index=1, recommendations=[Row(artistname_index=163412, rating=0.13188980519771576), Row(artistname_index=76809, rating=0.10977599024772644), Row(artistname_index=112985, rating=0.10864003002643585), Row(artistname_index=37366, rating=0.10733484476804733), Row(artistname_index=51082, rating=0.09390018880367279), Row(artistname_index=135095, rating=0.0905061587691307), Row(artistname_index=243033, rating=0.08670885115861893), Row(artistname_index=190699, rating=0.08421992510557175), Row(artistname_index=188137, rating=0.08420371264219284), Row(artistname_index=85883, rating=0.08340750634670258)]),\n",
              " Row(user_id_index=2, recommendations=[Row(artistname_index=51082, rating=0.05577825382351875), Row(artistname_index=76809, rating=0.05316533148288727), Row(artistname_index=149394, rating=0.05300728231668472), Row(artistname_index=126554, rating=0.04858596622943878), Row(artistname_index=101031, rating=0.047018200159072876), Row(artistname_index=89915, rating=0.04597727581858635), Row(artistname_index=85883, rating=0.044620268046855927), Row(artistname_index=33920, rating=0.0416952446103096), Row(artistname_index=250287, rating=0.041003886610269547), Row(artistname_index=119829, rating=0.040725190192461014)]),\n",
              " Row(user_id_index=3, recommendations=[Row(artistname_index=210588, rating=0.030846279114484787), Row(artistname_index=28600, rating=0.028309248387813568), Row(artistname_index=51082, rating=0.02540583349764347), Row(artistname_index=6178, rating=0.024118760600686073), Row(artistname_index=33914, rating=0.02337726205587387), Row(artistname_index=126554, rating=0.02053743600845337), Row(artistname_index=161852, rating=0.019279845058918), Row(artistname_index=135095, rating=0.018824901431798935), Row(artistname_index=157985, rating=0.017690397799015045), Row(artistname_index=10727, rating=0.017658183351159096)]),\n",
              " Row(user_id_index=4, recommendations=[Row(artistname_index=51082, rating=0.4566318988800049), Row(artistname_index=28600, rating=0.4060654640197754), Row(artistname_index=135095, rating=0.39582130312919617), Row(artistname_index=177187, rating=0.3942975699901581), Row(artistname_index=89362, rating=0.39415091276168823), Row(artistname_index=163412, rating=0.39120715856552124), Row(artistname_index=126554, rating=0.36608120799064636), Row(artistname_index=210588, rating=0.36477309465408325), Row(artistname_index=131896, rating=0.33749303221702576), Row(artistname_index=76809, rating=0.33517804741859436)]),\n",
              " Row(user_id_index=5, recommendations=[Row(artistname_index=37256, rating=0.3592250645160675), Row(artistname_index=32856, rating=0.357729971408844), Row(artistname_index=63174, rating=0.3001914918422699), Row(artistname_index=89025, rating=0.2927144169807434), Row(artistname_index=257149, rating=0.2921302318572998), Row(artistname_index=127166, rating=0.29011568427085876), Row(artistname_index=80387, rating=0.28227561712265015), Row(artistname_index=269792, rating=0.26432308554649353), Row(artistname_index=180982, rating=0.2621675431728363), Row(artistname_index=226782, rating=0.26152005791664124)]),\n",
              " Row(user_id_index=6, recommendations=[Row(artistname_index=59560, rating=0.10600991547107697), Row(artistname_index=51082, rating=0.10047482699155807), Row(artistname_index=203157, rating=0.0977829098701477), Row(artistname_index=169467, rating=0.09565585106611252), Row(artistname_index=252681, rating=0.0955275222659111), Row(artistname_index=177444, rating=0.09449592977762222), Row(artistname_index=32621, rating=0.09361398220062256), Row(artistname_index=63174, rating=0.08741925656795502), Row(artistname_index=269792, rating=0.08592982590198517), Row(artistname_index=67152, rating=0.0856465995311737)]),\n",
              " Row(user_id_index=8, recommendations=[Row(artistname_index=41327, rating=0.02837226539850235), Row(artistname_index=118249, rating=0.02811780944466591), Row(artistname_index=69899, rating=0.027686085551977158), Row(artistname_index=217000, rating=0.026888255029916763), Row(artistname_index=101546, rating=0.024137025699019432), Row(artistname_index=266207, rating=0.02337983436882496), Row(artistname_index=150028, rating=0.023266948759555817), Row(artistname_index=109823, rating=0.022870903834700584), Row(artistname_index=34153, rating=0.022860487923026085), Row(artistname_index=276726, rating=0.022809412330389023)]),\n",
              " Row(user_id_index=9, recommendations=[Row(artistname_index=89915, rating=0.008723069913685322), Row(artistname_index=101031, rating=0.007975384593009949), Row(artistname_index=85883, rating=0.007645925506949425), Row(artistname_index=17682, rating=0.007015491835772991), Row(artistname_index=285318, rating=0.006918910425156355), Row(artistname_index=149394, rating=0.00685532670468092), Row(artistname_index=76809, rating=0.006643352098762989), Row(artistname_index=112985, rating=0.006585936993360519), Row(artistname_index=192596, rating=0.006423609796911478), Row(artistname_index=252681, rating=0.006138001102954149)]),\n",
              " Row(user_id_index=10, recommendations=[Row(artistname_index=63521, rating=0.39124444127082825), Row(artistname_index=40206, rating=0.35592275857925415), Row(artistname_index=21058, rating=0.33048632740974426), Row(artistname_index=198927, rating=0.32979658246040344), Row(artistname_index=135095, rating=0.31560784578323364), Row(artistname_index=210588, rating=0.3098471164703369), Row(artistname_index=163412, rating=0.2912026345729828), Row(artistname_index=37366, rating=0.27047058939933777), Row(artistname_index=143141, rating=0.2605879306793213), Row(artistname_index=112985, rating=0.2553003132343292)]),\n",
              " Row(user_id_index=11, recommendations=[Row(artistname_index=210588, rating=0.5407277941703796), Row(artistname_index=63521, rating=0.5070255994796753), Row(artistname_index=135095, rating=0.4872817099094391), Row(artistname_index=198927, rating=0.47255939245224), Row(artistname_index=163412, rating=0.46511709690093994), Row(artistname_index=37366, rating=0.42496925592422485), Row(artistname_index=51082, rating=0.41263559460639954), Row(artistname_index=143141, rating=0.40880152583122253), Row(artistname_index=224027, rating=0.39110395312309265), Row(artistname_index=28600, rating=0.37720394134521484)])]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "(training, test) = normalized_pl_counts_df.randomSplit([0.8, 0.2])\n",
        "\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id_index\", itemCol=\"artistname_index\", ratingCol=\"normalized_reproduction\", coldStartStrategy=\"drop\",implicitPrefs=True)\n",
        "model = als.fit(training)\n",
        "\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"normalized_reproduction\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error (RMSE) = \" + str(rmse))\n",
        "\n",
        "#Top 10 recomendaciones por usuario\n",
        "userRecs = model.recommendForAllUsers(10)\n",
        "userRecs.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 recomendaiones para un usuario"
      ],
      "metadata": {
        "id": "ZX1X1Rrv3xJa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "x4nP51nB0dVF",
        "outputId": "3c3b0c73-9547-461d-977a-539b599e11b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+---------------+--------------------+\n",
            "|artistname_index|     artistname|recommendation_score|\n",
            "+----------------+---------------+--------------------+\n",
            "|          157985|        Madonna|          0.02455879|\n",
            "|           63174|    David Bowie|         0.023608776|\n",
            "|          210588|        Rihanna|         0.022057204|\n",
            "|          169467|Michael Jackson|          0.02189978|\n",
            "|           28600|        Beyonc√©|         0.021125346|\n",
            "|          164255|    Marvin Gaye|         0.020584796|\n",
            "|          236202|  Stevie Wonder|         0.020487295|\n",
            "|          143141|      Lady Gaga|         0.018550886|\n",
            "|           36605| Britney Spears|         0.017046666|\n",
            "|           17755|Aretha Franklin|         0.016739469|\n",
            "+----------------+---------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_id_index = 5914  # Usuario de ejemplo\n",
        "\n",
        "playlist_df = userRecs.filter(fn.col(\"user_id_index\") == user_id_index).select(fn.explode(\"recommendations\").alias(\"recommendation\"))\n",
        "playlist_df = dims['artistname'].join(playlist_df.select(fn.col(\"recommendation.artistname_index\").alias(\"artistname_index\"), fn.col(\"recommendation.rating\").alias(\"recommendation_score\")),'artistname_index')\\\n",
        "              .orderBy(\"recommendation_score\", ascending=False)\n",
        "playlist_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los artistas que ya ha reproducido el usuario."
      ],
      "metadata": {
        "id": "4DgXscuZ3m4i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vxwBZvOtptXH",
        "outputId": "6e2d8d53-da38-40e6-c52e-cb4253c0b613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------+\n",
            "|   artistname|reproductions|\n",
            "+-------------+-------------+\n",
            "|      Madonna|          290|\n",
            "|Talking Heads|          132|\n",
            "| Lana Del Rey|           12|\n",
            "|   Theme Park|            5|\n",
            "|  Hybrid Funk|            2|\n",
            "|     Smokeman|            1|\n",
            "+-------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "usr_reps = counts_df.filter(fn.col(\"user_id_index\") == user_id_index).distinct()\\\n",
        "    .join(dims['artistname'],'artistname_index').orderBy('reproductions', ascending=False).select('artistname','reproductions')\n",
        "\n",
        "usr_reps.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminando los artistas que el usuario ya ha reproducido\n",
        "\n",
        "print('Recomendaciones de artistas para el usuario:\\n')\n",
        "playlist_df.join(usr_reps, playlist_df[\"artistname\"] == usr_reps[\"artistname\"], \"left_anti\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TuTRi7S77rdr",
        "outputId": "58e9400d-6e9c-49ff-c2e8-6012056cd43e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recomendaciones de artistas para el usuario:\n",
            "\n",
            "+----------------+---------------+--------------------+\n",
            "|artistname_index|     artistname|recommendation_score|\n",
            "+----------------+---------------+--------------------+\n",
            "|           63174|    David Bowie|         0.023608776|\n",
            "|          210588|        Rihanna|         0.022057204|\n",
            "|          169467|Michael Jackson|          0.02189978|\n",
            "|           28600|        Beyonc√©|         0.021125346|\n",
            "|          164255|    Marvin Gaye|         0.020584796|\n",
            "|          236202|  Stevie Wonder|         0.020487295|\n",
            "|          143141|      Lady Gaga|         0.018550886|\n",
            "|           36605| Britney Spears|         0.017046666|\n",
            "|           17755|Aretha Franklin|         0.016739469|\n",
            "+----------------+---------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}