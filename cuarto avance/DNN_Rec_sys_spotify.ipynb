{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfLT2i0MLyD"
      },
      "source": [
        "# Instalando dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67T0090Jk2KL",
        "outputId": "0d8d68d9-9970-4260-d91c-24dfa9d0366d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 14 13:42:40 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0C8IV5TQnjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f9c20e-3d8c-4e8e-8017-13238161d4a9"
      },
      "source": [
        "# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n",
        "# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 485, done.\u001b[K\n",
            "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 485 (delta 146), reused 124 (delta 91), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (485/485), 134.51 KiB | 709.00 KiB/s, done.\n",
            "Resolving deltas: 100% (248/248), done.\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 715.7 kB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.0\n",
            "***********************************************************************\n",
            "Woo! Your instance has a Tesla T4 GPU!\n",
            "We will install the latest stable RAPIDS via pip 24.4.*!  Please stand by, should be quick...\n",
            "***********************************************************************\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Collecting cuml-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuml-cu12/cuml_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1200.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 GB 886.9 kB/s eta 0:00:00\n",
            "Collecting cugraph-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cugraph-cu12/cugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1429.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB 1.0 MB/s eta 0:00:00\n",
            "Collecting cuspatial-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuspatial-cu12/cuspatial_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.8/137.8 MB 7.6 MB/s eta 0:00:00\n",
            "Collecting cuproj-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuproj-cu12/cuproj_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 920.9/920.9 kB 69.8 MB/s eta 0:00:00\n",
            "Collecting cuxfilter-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuxfilter-cu12/cuxfilter_cu12-24.4.1-py3-none-any.whl (83 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.5/83.5 kB 13.8 MB/s eta 0:00:00\n",
            "Collecting cucim-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cucim-cu12/cucim_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 97.4 MB/s eta 0:00:00\n",
            "Collecting pylibraft-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/pylibraft-cu12/pylibraft_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (823.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.0/823.0 MB 1.3 MB/s eta 0:00:00\n",
            "Collecting raft-dask-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/raft-dask-cu12/raft_dask_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.1/170.1 MB 7.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.9.5)\n",
            "Requirement already satisfied: cudf-cu12==24.4.* in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (24.4.1)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (12.2.0)\n",
            "Collecting dask-cuda==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading dask_cuda-24.4.0-py3-none-any.whl (126 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.6/126.6 kB 3.8 MB/s eta 0:00:00\n",
            "Collecting dask-cudf-cu12==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/dask-cudf-cu12/dask_cudf_cu12-24.4.1-py3-none-any.whl (48 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 8.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.4.2)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (0.58.1)\n",
            "Collecting rapids-dask-dependency==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-24.4.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: rmm-cu12==24.4.* in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (24.4.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.11.4)\n",
            "Collecting treelite==4.1.2 (from cuml-cu12==24.4.*)\n",
            "  Downloading treelite-4.1.2-py3-none-manylinux2014_x86_64.whl (810 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 810.9/810.9 kB 9.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: fsspec[http]>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cugraph-cu12==24.4.*) (2023.6.0)\n",
            "Requirement already satisfied: numpy<2.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cugraph-cu12==24.4.*) (1.25.2)\n",
            "Collecting pylibcugraph-cu12==24.4.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/pylibcugraph-cu12/pylibcugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1430.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB 600.1 kB/s eta 0:00:00\n",
            "Collecting ucx-py-cu12==0.37.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/ucx-py-cu12/ucx_py_cu12-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 81.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: geopandas>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from cuspatial-cu12==24.4.*) (0.13.2)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (3.3.4)\n",
            "Collecting datashader>=0.15 (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading datashader-0.16.2-py2.py3-none-any.whl (18.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 57.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: holoviews>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.17.1)\n",
            "Collecting jupyter-server-proxy (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading jupyter_server_proxy-4.2.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (24.1)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.3.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (8.1.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (0.4)\n",
            "Requirement already satisfied: scikit-image<0.23.0a0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (0.19.3)\n",
            "Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /usr/local/lib/python3.10/dist-packages (from pylibraft-cu12==24.4.*) (12.2.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*->cuml-cu12==24.4.*) (5.3.3)\n",
            "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*->cuml-cu12==24.4.*) (0.2.10)\n",
            "Requirement already satisfied: pandas<2.2.2dev0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*->cuml-cu12==24.4.*) (2.0.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*->cuml-cu12==24.4.*) (3.20.3)\n",
            "Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*->cuml-cu12==24.4.*) (0.2.3)\n",
            "Requirement already satisfied: pyarrow<15.0.0a0,>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*->cuml-cu12==24.4.*) (14.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*->cuml-cu12==24.4.*) (13.7.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*->cuml-cu12==24.4.*) (4.12.2)\n",
            "Collecting pynvml<11.5,>=11.0.0 (from dask-cuda==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 7.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Collecting dask==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask-2024.1.1-py3-none-any.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 78.1 MB/s eta 0:00:00\n",
            "Collecting distributed==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading distributed-2024.1.1-py3-none-any.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 68.6 MB/s eta 0:00:00\n",
            "Collecting dask-expr==0.4.0 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask_expr-0.4.0-py3-none-any.whl (161 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.7/161.7 kB 20.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (7.1.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.1.4)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (1.2.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (9.4.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (2024.6.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<13.0a0,>=12.0->pylibraft-cu12==24.4.*) (3.0.10)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x>=12.0.0->cuml-cu12==24.4.*) (0.8.2)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (3.1.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.1.0)\n",
            "Collecting pyct (from datashader>=0.15->cuxfilter-cu12==24.4.*)\n",
            "  Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.31.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2023.7.0)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (1.9.6)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2.0.4)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from holoviews>=1.16.0->cuxfilter-cu12==24.4.*) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cuml-cu12==24.4.*) (0.41.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.6)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (4.66.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (6.1.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (1.6.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.7)\n",
            "Requirement already satisfied: jupyter-server>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.24.0)\n",
            "Collecting simpervisor>=1.0.0 (from jupyter-server-proxy->cuxfilter-cu12==24.4.*)\n",
            "  Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2024.6.2)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.1.5)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.2)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.10.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.20.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (24.0.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.18.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*->cuml-cu12==24.4.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*->cuml-cu12==24.4.*) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*->cuml-cu12==24.4.*) (2024.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->cuxfilter-cu12==24.4.*) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader>=0.15->cuxfilter-cu12==24.4.*) (3.3.2)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12==24.4.*->cuml-cu12==24.4.*) (2.16.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.19.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.12.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.19.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.18.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.22)\n",
            "Installing collected packages: simpervisor, pynvml, pyct, ucx-py-cu12, treelite, dask, pylibraft-cu12, distributed, dask-expr, cuproj-cu12, cucim-cu12, rapids-dask-dependency, pylibcugraph-cu12, datashader, cuspatial-cu12, dask-cudf-cu12, dask-cuda, raft-dask-cu12, cuml-cu12, cugraph-cu12, jupyter-server-proxy, cuxfilter-cu12\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.5.0\n",
            "    Uninstalling pynvml-11.5.0:\n",
            "      Successfully uninstalled pynvml-11.5.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2023.8.1\n",
            "    Uninstalling dask-2023.8.1:\n",
            "      Successfully uninstalled dask-2023.8.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2023.8.1\n",
            "    Uninstalling distributed-2023.8.1:\n",
            "      Successfully uninstalled distributed-2023.8.1\n",
            "Successfully installed cucim-cu12-24.4.0 cugraph-cu12-24.4.0 cuml-cu12-24.4.0 cuproj-cu12-24.4.0 cuspatial-cu12-24.4.0 cuxfilter-cu12-24.4.1 dask-2024.1.1 dask-cuda-24.4.0 dask-cudf-cu12-24.4.1 dask-expr-0.4.0 datashader-0.16.2 distributed-2024.1.1 jupyter-server-proxy-4.2.0 pyct-0.5.0 pylibcugraph-cu12-24.4.0 pylibraft-cu12-24.4.0 pynvml-11.4.1 raft-dask-cu12-24.4.0 rapids-dask-dependency-24.4.1 simpervisor-1.0.0 treelite-4.1.2 ucx-py-cu12-0.37.0\n",
            "\n",
            "        ***********************************************************************\n",
            "        The pip install of RAPIDS is complete.\n",
            "        \n",
            "        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n",
            "        \n",
            "        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n",
            "\n",
            "        Troubleshooting:\n",
            "            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n",
            "            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
            "        ***********************************************************************\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEtmd6fAuvUf",
        "outputId": "6fd3d4ac-c5aa-4409-e85d-dcfc27bc9c07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PftvXWLUkxC2",
        "outputId": "4ae5430b-4425-40c8-d6bf-8cc79fcb3348"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.16.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJMJ6BulmMn"
      },
      "source": [
        "# Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cudf\n",
        "import gc\n",
        "import cuml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "#from cuml.recommendation import AlternatingLeastSquares as cuALS\n",
        "#from cuml.preprocessing.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hmSOU2WMzVpC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DIR = \"/content/drive/MyDrive/MNA/BigData/Spotify_rec_sys/\"\n",
        "os.chdir(DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIQawtsS73m9",
        "outputId": "d7ae4f0f-edc3-4c05-c5b6-c1da0a23fdd1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = cudf.read_parquet(\"df.parquet\")\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "df.columns = [col.replace('\"', '').replace(' ','') for col in df.columns]\n",
        "\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3Ecd6NPk3YWp",
        "outputId": "ffa28ee6-c97a-44be-b9db-a4fa713f40d1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            user_id                        artistname  \\\n",
              "0  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
              "1  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
              "2  9cc0cfd4d7d7885102480dd99e7a90d6                      Tiffany Page   \n",
              "3  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
              "4  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
              "\n",
              "                                           trackname    playlistname  \n",
              "0               (The Angels Wanna Wear My) Red Shoes  HARD ROCK 2010  \n",
              "1  (What's So Funny 'Bout) Peace, Love And Unders...  HARD ROCK 2010  \n",
              "2                                   7 Years Too Late  HARD ROCK 2010  \n",
              "3                              Accidents Will Happen  HARD ROCK 2010  \n",
              "4                                             Alison  HARD ROCK 2010  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>artistname</th>\n",
              "      <th>trackname</th>\n",
              "      <th>playlistname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
              "      <td>Elvis Costello</td>\n",
              "      <td>(The Angels Wanna Wear My) Red Shoes</td>\n",
              "      <td>HARD ROCK 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
              "      <td>Elvis Costello &amp; The Attractions</td>\n",
              "      <td>(What's So Funny 'Bout) Peace, Love And Unders...</td>\n",
              "      <td>HARD ROCK 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
              "      <td>Tiffany Page</td>\n",
              "      <td>7 Years Too Late</td>\n",
              "      <td>HARD ROCK 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
              "      <td>Elvis Costello &amp; The Attractions</td>\n",
              "      <td>Accidents Will Happen</td>\n",
              "      <td>HARD ROCK 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
              "      <td>Elvis Costello</td>\n",
              "      <td>Alison</td>\n",
              "      <td>HARD ROCK 2010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear índices únicos para cada columna\n",
        "dims = {}\n",
        "\n",
        "def df_dim(df, input_col):\n",
        "    unique_vals = df[input_col].unique().reset_index(drop=True).reset_index()\n",
        "    unique_vals.columns = [f\"{input_col}_index\", input_col]\n",
        "    dims[input_col] = unique_vals\n",
        "\n",
        "for col_name in df.columns:\n",
        "    df_dim(df, col_name)\n",
        "\n",
        "for dim in dims.values():\n",
        "    print(dim.head(10))\n",
        "\n",
        "for key, df_dim in dims.items():\n",
        "    df_dim.to_parquet(f\"{key}_dim.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7_Z8gAACBMh",
        "outputId": "6c4e043b-61a9-4863-caf8-9250f02039e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id_index                           user_id\n",
            "0              0  9cc0cfd4d7d7885102480dd99e7a90d6\n",
            "1              1  07f0fc3be95dcd878966b1f9572ff670\n",
            "2              2  944c80d26922ae634d6ce445b1fdff7f\n",
            "3              3  c5cdf06b5f1836006ef2a2fe4f5ff103\n",
            "4              4  f3743cac98b7255c3c4a23be09dee7e6\n",
            "5              5  c50566d83fba17b20697039d5824db78\n",
            "6              6  83d7007a034208cdb13b7d3c29a02005\n",
            "7              7  fa73fc4253c0a155bf953a9d43d2a46e\n",
            "8              8  6d623100681e282b592c079594f03a89\n",
            "9              9  650c4d63a819dbb77cc15a87f407039a\n",
            "   artistname_index                        artistname\n",
            "0                 0                    Elvis Costello\n",
            "1                 1  Elvis Costello & The Attractions\n",
            "2                 2                      Tiffany Page\n",
            "3                 3                            Lissie\n",
            "4                 4                    Paul McCartney\n",
            "5                 5                          Joe Echo\n",
            "6                 6                      The Breakers\n",
            "7                 7                       The Coronas\n",
            "8                 8                     Crowded House\n",
            "9                 9                      Joshua Radin\n",
            "   trackname_index                                          trackname\n",
            "0                0               (The Angels Wanna Wear My) Red Shoes\n",
            "1                1  (What's So Funny 'Bout) Peace, Love And Unders...\n",
            "2                2                                   7 Years Too Late\n",
            "3                3                              Accidents Will Happen\n",
            "4                4                                             Alison\n",
            "5                5                                        All Be Okay\n",
            "6                6                                    Band On The Run\n",
            "7                7                                          Beautiful\n",
            "8                8  Blackbird - Live at CitiField, NYC - Digital A...\n",
            "9                9                                        Bright Side\n",
            "   playlistname_index    playlistname\n",
            "0                   0  HARD ROCK 2010\n",
            "1                   1        IOW 2012\n",
            "2                   2            2080\n",
            "3                   3            C418\n",
            "4                   4       Chill out\n",
            "5                   5       Classique\n",
            "6                   6      Daft Punk \n",
            "7                   7         Electro\n",
            "8                   8    Ghibli songs\n",
            "9                   9          Soirée\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Unir los índices al DataFrame original\n",
        "newdf = df.copy()\n",
        "\n",
        "for col_name in df.columns:\n",
        "    newdf = newdf.merge(dims[col_name], on=col_name, how='left').drop(columns=[col_name])\n",
        "\n",
        "newdf.columns = [f\"{col_name}_index\" for col_name in df.columns]\n",
        "\n",
        "# Mostrar las primeras filas del nuevo DataFrame\n",
        "print(newdf.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc_3bmU1-bDp",
        "outputId": "1df08fca-67cf-448e-e882-98d21e7e5c1d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id_index  artistname_index  trackname_index  playlistname_index\n",
            "0              5              1216             2910                  38\n",
            "1              5              1217             2911                  38\n",
            "2              5              1218             2912                  38\n",
            "3              5              1219             1941                  38\n",
            "4              5              1220             2913                  38\n",
            "5              5              1221             2914                  38\n",
            "6              5               995             2524                  38\n",
            "7              5               245             2915                  38\n",
            "8              5              1222             2916                  38\n",
            "9              5              1119             2917                  38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Liberar memoria de los DataFrames dims en cuDF\n",
        "dims.clear()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Dlv1oGrDCnB",
        "outputId": "b3592951-f942-4bd8-b07d-2cf84e9d4c92"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "382"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(newdf))\n",
        "artist_counts = newdf.groupby('artistname_index').size().reset_index(name='reproductions')\n",
        "\n",
        "# Filtrar los artistas con menos de 500 reproducciones\n",
        "popular_artists = artist_counts[artist_counts['reproductions'] >= 500]['artistname_index']\n",
        "\n",
        "# Filtrar el DataFrame original para mantener solo los artistas populares\n",
        "filtered_df = newdf[newdf['artistname_index'].isin(popular_artists)]\n",
        "\n",
        "# 2. Filtrar usuarios que no han escuchado al menos 10 artistas\n",
        "user_artist_counts = filtered_df.groupby('user_id_index').size().reset_index(name='artist_count')\n",
        "active_users = user_artist_counts[user_artist_counts['artist_count'] >= 10]['user_id_index']\n",
        "\n",
        "filtered_df = filtered_df[filtered_df['user_id_index'].isin(active_users.to_pandas())]\n",
        "print(len(filtered_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoDv7T-YrtGI",
        "outputId": "4d56f314-2932-4b5f-aa77-b82f64d36fd5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12868518\n",
            "8472974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar y contar reproducciones\n",
        "counts_df = filtered_df.groupby(['user_id_index', 'artistname_index']).size().reset_index(name='reproductions')\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame agregado\n",
        "print(counts_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNFUcRFpEHOR",
        "outputId": "d7bfd4e6-6199-4ff0-be9d-4f25b98ba39d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id_index  artistname_index  reproductions\n",
            "0          14704             11087              6\n",
            "1          15339              1333              1\n",
            "2           2128             11727              2\n",
            "3          13536              6203              2\n",
            "4           9157               312              8\n",
            "5           3061              3172              2\n",
            "6          14005               217              1\n",
            "7          12614              1172              1\n",
            "8          12665              2304              3\n",
            "9          13765               588              2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_reproduction = counts_df['reproductions'].max()\n",
        "min_reproduction = counts_df['reproductions'].min()\n",
        "\n",
        "# Asegurarse de que max_reproduction y min_reproduction sean valores numéricos\n",
        "max_reproduction = float(max_reproduction)\n",
        "min_reproduction = float(min_reproduction)\n",
        "\n",
        "# Crear una copia de counts_df para agregar la columna normalizada\n",
        "normalized_pl_counts_df = counts_df.copy()\n",
        "\n",
        "# Calcular y agregar la columna normalizada\n",
        "normalized_pl_counts_df['normalized_reproduction'] = (normalized_pl_counts_df['reproductions'] - min_reproduction) / (max_reproduction - min_reproduction)\n",
        "\n",
        "normalized_pl_counts_df['log_normalized_reproduction'] = np.log1p(normalized_pl_counts_df['normalized_reproduction'].to_pandas())\n",
        "\n",
        "# Convertir de nuevo a cudf si es necesario\n",
        "normalized_pl_counts_df = cudf.DataFrame.from_pandas(normalized_pl_counts_df)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame resultante\n",
        "print(normalized_pl_counts_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf1Z4JL2FEbY",
        "outputId": "b9e473bc-e225-455b-c34d-f6e1b41bb1d4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id_index  artistname_index  reproductions  normalized_reproduction  \\\n",
            "0          14704             11087              6                 0.001495   \n",
            "1          15339              1333              1                 0.000000   \n",
            "2           2128             11727              2                 0.000299   \n",
            "3          13536              6203              2                 0.000299   \n",
            "4           9157               312              8                 0.002093   \n",
            "5           3061              3172              2                 0.000299   \n",
            "6          14005               217              1                 0.000000   \n",
            "7          12614              1172              1                 0.000000   \n",
            "8          12665              2304              3                 0.000598   \n",
            "9          13765               588              2                 0.000299   \n",
            "\n",
            "   log_normalized_reproduction  \n",
            "0                     0.001494  \n",
            "1                     0.000000  \n",
            "2                     0.000299  \n",
            "3                     0.000299  \n",
            "4                     0.002090  \n",
            "5                     0.000299  \n",
            "6                     0.000000  \n",
            "7                     0.000000  \n",
            "8                     0.000598  \n",
            "9                     0.000299  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#liberando memoria\n",
        "del counts_df\n",
        "newdf.to_parquet(f\"clean_df.parquet\")\n",
        "del newdf\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2e1ye2gFjnB",
        "outputId": "46517109-f8e0-4617-b78b-a5484a509863"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_users = normalized_pl_counts_df['user_id_index'].unique()\n",
        "\n",
        "# Dividir los usuarios en tres conjuntos: entrenamiento, validación y prueba\n",
        "train_users, temp_users = train_test_split(unique_users, test_size=0.3, random_state=42)\n",
        "val_users, test_users = train_test_split(temp_users, test_size=0.5, random_state=42)\n",
        "\n",
        "# Filtrar los DataFrames originales en base a los conjuntos de usuarios\n",
        "train_df = normalized_pl_counts_df[normalized_pl_counts_df['user_id_index'].isin(train_users)]\n",
        "val_df = normalized_pl_counts_df[normalized_pl_counts_df['user_id_index'].isin(val_users)]\n",
        "test_df = normalized_pl_counts_df[normalized_pl_counts_df['user_id_index'].isin(test_users)]\n",
        "\n",
        "X_train_pd = train_df[['user_id_index', 'artistname_index']]\n",
        "y_train_pd = train_df['log_normalized_reproduction']\n",
        "\n",
        "X_test_pd = test_df[['user_id_index', 'artistname_index']]\n",
        "y_test_pd = test_df['log_normalized_reproduction']\n",
        "\n",
        "X_val_pd = val_df[['user_id_index', 'artistname_index']]\n",
        "y_val_pd = val_df['log_normalized_reproduction']\n",
        "\n",
        "# Convertir los DataFrames de train y test de nuevo a cudf\n",
        "X_train = cudf.DataFrame.from_pandas(X_train_pd)\n",
        "X_test = cudf.DataFrame.from_pandas(X_test_pd)\n",
        "X_val = cudf.DataFrame.from_pandas(X_val_pd)\n",
        "\n",
        "y_train = cudf.Series(y_train_pd)\n",
        "y_test = cudf.Series(y_test_pd)\n",
        "y_val = cudf.Series(y_val_pd)\n",
        "\n",
        "# Liberar memoria\n",
        "del X_train_pd, y_train_pd, X_test_pd, y_test_pd, X_val_pd, y_val_pd\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "print(f\"Train set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_val)}\")\n",
        "print(f\"Val set size: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z9WuiyEIL9h",
        "outputId": "f0dd798f-e9a9-4343-d123-8fd9596a65a0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 1225176\n",
            "Test set size: 278052\n",
            "Val set size: 256978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entrenamiento de Red Neuronal Densa"
      ],
      "metadata": {
        "id": "BAcY-nCuaYTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = X_train[\"user_id_index\"].nunique()  # Count unique user IDs\n",
        "num_items = X_train[\"artistname_index\"].nunique()  # Count unique item IDs\n",
        "embedding_dim = 100"
      ],
      "metadata": {
        "id": "gM3C2CqNnmCp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_users)\n",
        "print(num_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHvTzJy3oydA",
        "outputId": "54bc1753-5772-441b-f611-b7392e4a645a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10117\n",
            "4039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Entradas\n",
        "user_input = layers.Input(shape=(1,))  # ID de usuario como un único entero\n",
        "item_input = layers.Input(shape=(1,))  # ID de artista como un único entero\n",
        "\n",
        "# Capas de embeddings\n",
        "user_embedding = layers.Embedding(num_users, embedding_dim)(user_input)\n",
        "item_embedding = layers.Embedding(num_items, embedding_dim)(item_input)\n",
        "\n",
        "# Aplanar los embeddings (los embeddings de entrada tienen forma (batch_size, 1, embedding_dim))\n",
        "user_embedding = layers.Flatten()(user_embedding)\n",
        "item_embedding = layers.Flatten()(item_embedding)\n",
        "\n",
        "# Concatenar los embeddings aplanados\n",
        "merged = layers.concatenate([user_embedding, item_embedding])\n",
        "\n",
        "# Capas ocultas y capa de salida\n",
        "x = layers.Dense(128, activation=\"relu\")(merged)\n",
        "output = layers.Dense(1)(x)  # Capa de salida para predicciones\n",
        "\n",
        "# Definir el modelo\n",
        "model = Model(inputs=[user_input, item_input], outputs=output)\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "# Mostrar el resumen del modelo\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "UcXuTW8gmaf4",
        "outputId": "5a191631-04cd-401d-f9e9-c75aeac72d07"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │      \u001b[38;5;34m1,011,700\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │        \u001b[38;5;34m403,900\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m25,728\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,011,700</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">403,900</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25,728</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,441,457\u001b[0m (5.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,441,457</span> (5.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,441,457\u001b[0m (5.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,441,457</span> (5.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[X_train.to_numpy()[:, 0], X_train.to_numpy()[:, 1]], y=y_train.to_numpy(), epochs=10, validation_data=([X_val.to_numpy()[:, 0], X_val.to_numpy()[:, 1]], y_val.to_numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXieKzdRxNWn",
        "outputId": "85077792-11d7-4155-b942-4316b747936c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2ms/step - loss: 3.1052e-05 - val_loss: 1.4710e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 2.1676e-05 - val_loss: 1.4307e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - loss: 1.8695e-05 - val_loss: 1.4605e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2ms/step - loss: 2.1182e-05 - val_loss: 1.4926e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2ms/step - loss: 2.3242e-05 - val_loss: 1.4565e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 2ms/step - loss: 2.0549e-05 - val_loss: 1.4324e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2ms/step - loss: 2.1104e-05 - val_loss: 1.4278e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2ms/step - loss: 2.1109e-05 - val_loss: 1.4711e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2ms/step - loss: 2.0868e-05 - val_loss: 1.4469e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2ms/step - loss: 2.0287e-05 - val_loss: 1.5410e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d0ab04e68f0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluando el modelo"
      ],
      "metadata": {
        "id": "WXmiI_WkZ16N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "predicted_reproductions = model.predict([X_train['user_id_index'].to_numpy(), X_train['artistname_index'].to_numpy()])\n",
        "\n",
        "# Calcular el error cuadrático medio (MSE) para todo el conjunto de prueba\n",
        "mse = mean_squared_error(y_train.to_numpy(), predicted_reproductions)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) X_train: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNnTjY0QZ5D-",
        "outputId": "b232af6a-bb8c-43a5-a694-901a0fa76f9a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38287/38287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2ms/step\n",
            "Mean Squared Error (MSE) X_train: 2.0108257168224288e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "pred_X_test = model.predict([X_test['user_id_index'].to_numpy(), X_test['artistname_index'].to_numpy()])\n",
        "\n",
        "# Calcular el error cuadrático medio (MSE) para todo el conjunto de prueba\n",
        "mse = mean_squared_error(y_test.to_numpy(), pred_X_test)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE) X_test: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DgiZ4o2Z66m",
        "outputId": "1ff8c86d-9059-4505-cd13-b14975a93810"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8031/8031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
            "Mean Squared Error (MSE) X_test: 1.917968769151336e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluando predicciones"
      ],
      "metadata": {
        "id": "WDb8p1rmcnK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar los ususarios que no fueron vistos durante el entrenamiento se crea matriz de similitud entre ussuarios según los artistas que escuchan.\n",
        "\n",
        "Para un nuevo usuario se busca un usuario similar conocido y se brindan las recomendaciones de este último"
      ],
      "metadata": {
        "id": "Z225cB8tNiw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matriz de similitud"
      ],
      "metadata": {
        "id": "hbdB6rUYOB21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([train_df.to_pandas(), test_df.to_pandas()])"
      ],
      "metadata": {
        "id": "nBPAlCw4jMuf"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_matrix = combined_df.pivot(index='user_id_index', columns='artistname_index', values='log_normalized_reproduction').fillna(0)\n"
      ],
      "metadata": {
        "id": "2wQjz2aZapmR"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_similarity = cosine_similarity(interaction_matrix)\n",
        "\n",
        "user_similarity_df = pd.DataFrame(user_similarity, index=interaction_matrix.index, columns=interaction_matrix.index)"
      ],
      "metadata": {
        "id": "FXaSs7thj_PH"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_similarity_df = cudf.DataFrame.from_pandas(user_similarity_df)"
      ],
      "metadata": {
        "id": "WVwtjuUV0UXd"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del user_similarity\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttn0SsuR9P8c",
        "outputId": "55513927-979f-43a1-f1ee-07e73df586f8"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar este modelo se utillizaran 3 metricas:\n",
        "- Presision@K\n",
        "- Mean Average Precision (MAP)\n",
        "- Normalized Discounted Cumulative Gain (NDCG)"
      ],
      "metadata": {
        "id": "62e34CbYPl_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precision@K"
      ],
      "metadata": {
        "id": "7TvT8bPwOPLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cudf\n",
        "\n",
        "\n",
        "def get_recommendations_for_new_user(user_id, user_similarity_df, model, num_items, top_k=10):\n",
        "\n",
        "    similar_users = user_similarity_df[user_id].sort_values(ascending=False).head(top_k + 1).index.to_arrow().to_pylist()\n",
        "    similar_users.remove(user_id)\n",
        "\n",
        "\n",
        "    similar_user_predictions = np.zeros(num_items)\n",
        "    for similar_user in similar_users:\n",
        "        predictions = model.predict([np.array([similar_user] * num_items), np.arange(num_items)], verbose=0)\n",
        "        similar_user_predictions += predictions.flatten()\n",
        "\n",
        "\n",
        "    recommendations = np.argsort(similar_user_predictions)[::-1][:top_k]\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "def precision_at_k(recommendations, actual_artists, k=10):\n",
        "    num_correct = len(set(recommendations).intersection(actual_artists))\n",
        "    precision = num_correct / k\n",
        "    return precision\n",
        "\n",
        "\n",
        "random_users_to_evaluate = np.random.choice(test_df['user_id_index'].unique().to_arrow().to_pylist(), size=100, replace=False)\n",
        "\n",
        "\n",
        "k=10\n",
        "precisions = []\n",
        "for user_id in random_users_to_evaluate:\n",
        "    actual_artists = test_df[test_df['user_id_index'] == user_id]['artistname_index'].to_arrow().to_pylist()\n",
        "    recommendations = get_recommendations_for_new_user(user_id, user_similarity_df, model, num_items, top_k=k)\n",
        "    precisions.append(precision_at_k(recommendations, actual_artists, k))\n",
        "\n",
        "mean_precision_at_k = np.mean(precisions)\n",
        "print(f\"Mean Precision@{k}: {mean_precision_at_k}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uytXE-Mk9Y8F",
        "outputId": "515057e2-029f-4a12-8a95-3da511d595bb"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Precision@10: 0.4331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MAP@K (Mean Average Precision)"
      ],
      "metadata": {
        "id": "wjs6Xr2XOYBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average_precision_at_k(recommendations, actual_artists, k=10):\n",
        "    num_correct = 0\n",
        "    precision_sum = 0.0\n",
        "    for i in range(k):\n",
        "        artist_id = recommendations[i] if i < len(recommendations) else None\n",
        "        if artist_id in actual_artists:\n",
        "            num_correct += 1\n",
        "            precision_sum += num_correct / (i + 1)  # Precision at i+1\n",
        "    if not actual_artists:\n",
        "        return 0.0\n",
        "    return precision_sum / min(len(actual_artists), k)\n",
        "\n",
        "def mean_average_precision_at_k(recommendations_list, actual_artists_list, k=10):\n",
        "    total_map = 0.0\n",
        "    for recommendations, actual_artists in zip(recommendations_list, actual_artists_list):\n",
        "        ap = average_precision_at_k(recommendations, actual_artists, k)\n",
        "        total_map += ap\n",
        "\n",
        "    mean_map = total_map / len(recommendations_list)\n",
        "    return mean_map\n",
        "\n",
        "# Uso de la función\n",
        "precisions = []\n",
        "for user_id in random_users_to_evaluate:\n",
        "    actual_artists = test_df[test_df['user_id_index'] == user_id]['artistname_index'].to_arrow().to_pylist()\n",
        "    recommendations = get_recommendations_for_new_user(user_id, user_similarity_df, model, num_items, top_k=k).tolist()\n",
        "    precisions.append((recommendations, actual_artists))\n",
        "\n",
        "map_at_k = mean_average_precision_at_k([recs for recs, _ in precisions], [arts for _, arts in precisions], k)\n",
        "print(f\"Mean Average Precision@{k}: {map_at_k}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Orn7qfNoBRPY",
        "outputId": "b817e7d9-b35a-43fd-e442-024e585ee5dc"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Average Precision@10: 0.1004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NDGC@K (Normalized Discounted Cumulative Gain)"
      ],
      "metadata": {
        "id": "BrmsBey0Odq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def dcg_at_k(predichos, k):\n",
        "    if not isinstance(predichos, list) or len(predichos) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    dcg = predichos[0] if isinstance(predichos[0], (int, float)) else 0.0\n",
        "\n",
        "    for i in range(1, min(k, len(predichos))):\n",
        "        if isinstance(predichos[i], (int, float)):\n",
        "            dcg += predichos[i] / math.log2(i + 1)\n",
        "\n",
        "    return dcg\n",
        "\n",
        "def ndcg_at_k(predichos, reales, k):\n",
        "    dcg_predichos = dcg_at_k(predichos, k)\n",
        "    dcg_reales = dcg_at_k(reales, k)\n",
        "    if dcg_reales == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        ndcg = dcg_predichos / dcg_reales\n",
        "        return ndcg\n",
        "\n",
        "def ndcg_at_k_promedio_acumulado(predichos, reales, k, total_usuarios):\n",
        "\n",
        "    global_sum = 0.0\n",
        "    ndcg = ndcg_at_k(predichos, reales, k)\n",
        "    global_sum += ndcg\n",
        "\n",
        "    if total_usuarios == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        ndcg_promedio = global_sum / total_usuarios\n",
        "        return ndcg_promedio\n",
        "\n",
        "\n",
        "total_usuarios = 0\n",
        "actual_artists_l = []\n",
        "recommendations_l = []\n",
        "\n",
        "\n",
        "for user_id in random_users_to_evaluate:\n",
        "    actual_artists = test_df[test_df['user_id_index'] == user_id]['artistname_index'].to_arrow().to_pylist()\n",
        "    recommendations = get_recommendations_for_new_user(user_id, user_similarity_df, model, num_items, top_k=k).tolist()\n",
        "\n",
        "\n",
        "    actual_artists_l.append(actual_artists)\n",
        "    recommendations_l.append(recommendations)\n",
        "    total_usuarios += 1\n",
        "\n",
        "\n",
        "ndcg_promedio_acumulado = ndcg_at_k_promedio_acumulado(actual_artists_l, recommendations_l, 10, total_usuarios)\n",
        "print(f\"NDCG@10 promedio acumulado = {ndcg_promedio_acumulado:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17n6wo-TJu5m",
        "outputId": "7f761e7b-59fc-4329-a771-fc71af38265d"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG@10 promedio acumulado = 0.0588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementación\n",
        "\n",
        "A continuacion se muestra cómo el modelo genera recomendaciones para un nuevo usuario:"
      ],
      "metadata": {
        "id": "natL8zUiO3nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cargando el catalogo de artistas:\n",
        "artist_dim = cudf.read_parquet(\"artistname_dim.parquet\")\n",
        "artist_dim.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rjaDTXh2QWS-",
        "outputId": "0a815aa9-757a-47e0-80f4-de93171b0d7c"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   artistname_index                        artistname\n",
              "0                 0                    Elvis Costello\n",
              "1                 1  Elvis Costello & The Attractions\n",
              "2                 2                      Tiffany Page\n",
              "3                 3                            Lissie\n",
              "4                 4                    Paul McCartney"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artistname_index</th>\n",
              "      <th>artistname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Elvis Costello</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Elvis Costello &amp; The Attractions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Tiffany Page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Lissie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Paul McCartney</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "A-rB85EaPHTc",
        "outputId": "cebf987c-b190-4496-8491-2b9b34b1608a"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    user_id_index  artistname_index  reproductions  normalized_reproduction  \\\n",
              "8           12665              2304              3                 0.000598   \n",
              "27          14875              1021              2                 0.000299   \n",
              "36           8271               763             18                 0.005082   \n",
              "37           7171              2569              7                 0.001794   \n",
              "39           1663               699             12                 0.003288   \n",
              "\n",
              "    log_normalized_reproduction  \n",
              "8                      0.000598  \n",
              "27                     0.000299  \n",
              "36                     0.005069  \n",
              "37                     0.001792  \n",
              "39                     0.003283  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id_index</th>\n",
              "      <th>artistname_index</th>\n",
              "      <th>reproductions</th>\n",
              "      <th>normalized_reproduction</th>\n",
              "      <th>log_normalized_reproduction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12665</td>\n",
              "      <td>2304</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>0.000598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>14875</td>\n",
              "      <td>1021</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000299</td>\n",
              "      <td>0.000299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>8271</td>\n",
              "      <td>763</td>\n",
              "      <td>18</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>0.005069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>7171</td>\n",
              "      <td>2569</td>\n",
              "      <td>7</td>\n",
              "      <td>0.001794</td>\n",
              "      <td>0.001792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1663</td>\n",
              "      <td>699</td>\n",
              "      <td>12</td>\n",
              "      <td>0.003288</td>\n",
              "      <td>0.003283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ususario de prueba\n",
        "usr=14875\n",
        "recs = get_recommendations_for_new_user(usr, user_similarity_df, model, num_items, top_k=10)\n",
        "\n",
        "recs_df = cudf.DataFrame(recs,columns=['artistname_index'])\n",
        "\n",
        "joined_data = cudf.merge(recs_df, artist_dim, on='artistname_index')\n",
        "\n",
        "print(joined_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrvbQUQaP2Y9",
        "outputId": "6973adbf-4622-475c-f55c-2a581a34c1ac"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   artistname_index               artistname\n",
            "0              3952                 Funky DL\n",
            "1              3234           Rockabye Baby!\n",
            "2                98  Wolfgang Amadeus Mozart\n",
            "3              3268              Glenn Gould\n",
            "4               706          Håkan Hellström\n",
            "5               892          Lars Winnerbäck\n",
            "6               210              Murray Gold\n",
            "7               218   Vitamin String Quartet\n",
            "8              2480                   Lucero\n",
            "9               193                In Flames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist=test_df[test_df['user_id_index']==usr]['artistname_index'].unique()\n",
        "\n",
        "hist_df = cudf.DataFrame(hist,columns=['artistname_index'])\n",
        "\n",
        "joined_data = cudf.merge(hist_df, artist_dim, on='artistname_index')\n",
        "\n",
        "print(joined_data[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qO8Exr2QR5N",
        "outputId": "89b6abdb-436d-4c23-a750-b547e9db3c62"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    artistname_index               artistname\n",
            "0               1791               Snoop Dogg\n",
            "1                428             Frank Turner\n",
            "2               1457        Frightened Rabbit\n",
            "3                616        The Lonely Island\n",
            "4                835            NEEDTOBREATHE\n",
            "5                579            One Direction\n",
            "6                583        Simon & Garfunkel\n",
            "7               1736      Of Monsters and Men\n",
            "8               4303              John Legend\n",
            "9               2293             Dan Auerbach\n",
            "10              1183                Parachute\n",
            "11               189                    Gotye\n",
            "12              2799                     Fun.\n",
            "13              3138           Britney Spears\n",
            "14              4771               Macklemore\n",
            "15              2410       The Mountain Goats\n",
            "16               636                 Ron Pope\n",
            "17              1007                  Pitbull\n",
            "18               773         The Chainsmokers\n",
            "19               476  Macklemore & Ryan Lewis\n",
            "20               477        A Great Big World\n",
            "21               516                 Kodaline\n",
            "22              2209         Childish Gambino\n",
            "23              2972             Tyrone Wells\n",
            "24               668             Idina Menzel\n",
            "25             10325               Tyler Ward\n",
            "26               453             Taylor Swift\n",
            "27              2168               Aloe Blacc\n",
            "28               433           Flogging Molly\n",
            "29               439               Ed Sheeran\n",
            "30               694                 Flo Rida\n",
            "31               696             Fall Out Boy\n",
            "32              1021                   Eminem\n",
            "33              1017                will.i.am\n",
            "34             18169               Chris Rock\n"
          ]
        }
      ]
    }
  ]
}