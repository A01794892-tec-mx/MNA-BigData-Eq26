{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Instalando Dependencias"
      ],
      "metadata": {
        "id": "Q0Xv8Tto_22V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pVQjJoM_B5H"
      },
      "source": [
        "Instalando Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "F1Y1pRcivb5z",
        "outputId": "9d56238d-f76e-44e5-dae1-943e168238ff",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0Ô∏è‚É£   Install Java if not available\n",
            "‚úÖ Java is already installed.\n",
            "\n",
            "1Ô∏è‚É£   Download and install Hadoop and Spark\n",
            "‚úÖ https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz was found\n",
            "‚úÖ File ‚Äòspark-3.5.1-bin-hadoop3.tgz‚Äô already there; not retrieving.\n",
            "‚úÖ Folder already exists\n",
            "\n",
            "2Ô∏è‚É£   Start Spark engine\n",
            "‚úÖ stopping org.apache.spark.deploy.master.Master\n",
            "‚úÖ starting org.apache.spark.deploy.master.Master, logging to /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.master.Master-1-20866ca1a172.out\n",
            "‚úÖ stopping org.apache.spark.deploy.worker.Worker\n",
            "‚úÖ starting org.apache.spark.deploy.worker.Worker, logging to /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.worker.Worker-1-20866ca1a172.out\n",
            "\n",
            "3Ô∏è‚É£   Start Master Web UI\n",
            "Search for port number in log file /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.master.Master-1-20866ca1a172.out\n",
            "‚úÖ Master UI is available at localhost:8081 (attempt nr. 4)\n",
            "Click on the link below to open the Spark Web UI üöÄ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8081, \"/\", \"https://localhost:8081/\", window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4Ô∏è‚É£   Start history server\n",
            "‚úÖ stopping org.apache.spark.deploy.history.HistoryServer\n",
            "‚úÖ starting org.apache.spark.deploy.history.HistoryServer, logging to /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.history.HistoryServer-1-20866ca1a172.out\n",
            "Click on the link below to open the Spark History Server Web UI üöÄ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(18080, \"/\", \"https://localhost:18080/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import requests\n",
        "import subprocess\n",
        "import os\n",
        "import re\n",
        "import socket\n",
        "import shutil\n",
        "import time\n",
        "import sys\n",
        "\n",
        "def run(cmd):\n",
        "    # run a shell command\n",
        "    try:\n",
        "        # Run the command and capture stdout and stderr\n",
        "        subprocess_output = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        # Access stdout (stderr redirected to stdout)\n",
        "        stdout_result = subprocess_output.stdout.strip().splitlines()[-1]\n",
        "        # Process the results as needed\n",
        "        print(f'‚úÖ {stdout_result}')\n",
        "        return stdout_result\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # Handle the error if the command returns a non-zero exit code\n",
        "        print(f\"Command failed with return code {e.returncode}\")\n",
        "        print(\"stdout:\", e.stdout)\n",
        "\n",
        "def is_java_installed():\n",
        "    return shutil.which(\"java\")\n",
        "\n",
        "def install_java():\n",
        "    # Uncomment and modify the desired version\n",
        "    # java_version= 'openjdk-11-jre-headless'\n",
        "    # java_version= 'default-jre'\n",
        "    # java_version= 'openjdk-17-jre-headless'\n",
        "    # java_version= 'openjdk-18-jre-headless'\n",
        "    java_version= 'openjdk-19-jre-headless'\n",
        "    os.environ['JAVA_HOME'] = ' /usr/lib/jvm/java-19-openjdk-amd64'\n",
        "    print(f\"Java not found. Installing {java_version} ... (this might take a while)\")\n",
        "    try:\n",
        "        cmd = f\"apt install -y {java_version}\"\n",
        "        subprocess_output = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        stdout_result = subprocess_output.stdout\n",
        "        # Process the results as needed\n",
        "        print(f'‚úÖ Done installing Java {java_version}')\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # Handle the error if the command returns a non-zero exit code\n",
        "        print(f\"Command failed with return code {e.returncode}\")\n",
        "        print(\"stdout:\", e.stdout)\n",
        "\n",
        "print(\"\\n0Ô∏è‚É£   Install Java if not available\")\n",
        "if is_java_installed():\n",
        "    print(\"‚úÖ Java is already installed.\")\n",
        "else:\n",
        "    install_java()\n",
        "\n",
        "print(\"\\n1Ô∏è‚É£   Download and install Hadoop and Spark\")\n",
        "# URL for downloading Hadoop and Spark\n",
        "SPARK_VERSION = \"3.5.1\"\n",
        "HADOOP_SPARK_URL = \"https://dlcdn.apache.org/spark/spark-\" + SPARK_VERSION + \\\n",
        "                   \"/spark-\" + SPARK_VERSION + \"-bin-hadoop3.tgz\"\n",
        "r = requests.head(HADOOP_SPARK_URL)\n",
        "if r.status_code >= 200 and r.status_code < 400:\n",
        "    print(f'‚úÖ {HADOOP_SPARK_URL} was found')\n",
        "else:\n",
        "    SPARK_CDN = \"https://dlcdn.apache.org/spark/\"\n",
        "    print(f'‚ö†Ô∏è {HADOOP_SPARK_URL} was NOT found. \\nCheck for available Spark versions in {SPARK_CDN}')\n",
        "\n",
        "# set some environment variables\n",
        "os.environ['SPARK_HOME'] = os.path.join(os.getcwd(), os.path.splitext(os.path.basename(HADOOP_SPARK_URL))[0])\n",
        "os.environ['PATH'] = ':'.join([os.path.join(os.environ['SPARK_HOME'], 'bin'), os.environ['PATH']])\n",
        "os.environ['PATH'] = ':'.join([os.path.join(os.environ['SPARK_HOME'], 'sbin'), os.environ['PATH']])\n",
        "\n",
        "# download Spark\n",
        "# using --no-clobber option will prevent wget from downloading file if already present\n",
        "# shell command: wget --no-clobber $HADOOP_SPARK_URL\n",
        "cmd = f\"wget --no-clobber {HADOOP_SPARK_URL}\"\n",
        "run(cmd)\n",
        "\n",
        "# uncompress\n",
        "try:\n",
        "    # Run the command and capture stdout and stderr\n",
        "    cmd = \"([ -d $(basename {0}|sed 's/\\.[^.]*$//') ] && echo -n 'Folder already exists') || (tar xzf $(basename {0}) && echo 'Uncompressed Spark distribution')\"\n",
        "    subprocess_output = subprocess.run(cmd.format(HADOOP_SPARK_URL), shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    # Access stdout (stderr redirected to stdout)\n",
        "    stdout_result = subprocess_output.stdout\n",
        "    # Process the results as needed\n",
        "    print(f'‚úÖ {stdout_result}')\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    # Handle the error if the command returns a non-zero exit code\n",
        "    print(f\"Command failed with return code {e.returncode}\")\n",
        "    print(\"stdout:\", e.stdout)\n",
        "\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£   Start Spark engine\")\n",
        "# start master\n",
        "# shell command: $SPARK_HOME/sbin/start-master.sh\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'stop-master.sh')\n",
        "run(cmd)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'start-master.sh')\n",
        "out = run(cmd)\n",
        "\n",
        "# start one worker (first stop it in case it's already running)\n",
        "# shell command: $SPARK_HOME/sbin/start-worker.sh spark://${HOSTNAME}:7077\n",
        "cmd = [os.path.join(os.environ['SPARK_HOME'], 'sbin', 'stop-worker.sh')]\n",
        "run(cmd)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'start-worker.sh') + ' ' + 'spark://'+socket.gethostname()+':7077'\n",
        "run(cmd)\n",
        "\n",
        "print(\"\\n3Ô∏è‚É£   Start Master Web UI\")\n",
        "# get master UI's port number\n",
        "# the subprocess that's starting the master with start-master.sh\n",
        "# might still not be ready with assigning the port number at this point\n",
        "# therefore we check the logfile a few times (attempts=5) to see if the port\n",
        "# has been assigned. This might take 1-2 seconds.\n",
        "\n",
        "master_log = out.partition(\"logging to\")[2].strip()\n",
        "print(\"Search for port number in log file {}\".format(master_log))\n",
        "attempts = 10\n",
        "search_pattern = \"Successfully started service 'MasterUI' on port (\\d+)\"\n",
        "found = False\n",
        "for i in range(attempts):\n",
        "  if not found:\n",
        "   with open(master_log) as log:\n",
        "      found = re.search(search_pattern, log.read())\n",
        "      if found:\n",
        "          webUIport = found.group(1)\n",
        "          print(f\"‚úÖ Master UI is available at localhost:{webUIport} (attempt nr. {i})\")\n",
        "          break\n",
        "      else:\n",
        "          time.sleep(2) # need to try until port information is found in the logfile\n",
        "          i+=1\n",
        "if not found:\n",
        "  print(\"Could not find port for Master Web UI\\n\")\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    # serve the Web UI on Colab\n",
        "    print(\"Click on the link below to open the Spark Web UI üöÄ\")\n",
        "    from google.colab import output\n",
        "    output.serve_kernel_port_as_window(webUIport)\n",
        "\n",
        "print(\"\\n4Ô∏è‚É£   Start history server\")\n",
        "# start history server\n",
        "# shell command: mkdir -p /tmp/spark-events\n",
        "# shell command: $SPARK_HOME/sbin/start-history-server.sh\n",
        "spark_events_dir = os.path.join('/tmp', 'spark-events')\n",
        "if not os.path.exists(spark_events_dir):\n",
        "    os.mkdir(spark_events_dir)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'stop-history-server.sh')\n",
        "run(cmd)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'start-history-server.sh')\n",
        "run(cmd)\n",
        "\n",
        "if IN_COLAB:\n",
        "    # serve the History Server\n",
        "    print(\"Click on the link below to open the Spark History Server Web UI üöÄ\")\n",
        "    output.serve_kernel_port_as_window(18080)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8kmJakDEV_S",
        "outputId": "99969877-08e2-4338-dcac-01ee8af24dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n"
          ]
        }
      ],
      "source": [
        "pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD7Wr-eWUHO8",
        "outputId": "b8992dae-bea4-4f3f-f46a-e1c12c39bc14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocesamiento"
      ],
      "metadata": {
        "id": "WfqD-JjsAzqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LwSZ4HXFaDx"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as fn\n",
        "import os\n",
        "from pyspark.conf import SparkConf\n",
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOYEaGu_w97s",
        "outputId": "fc224d13-320a-4e20-ab05-e5184a08cbc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./spotify-playlists\" (use force=True to force download)\n"
          ]
        }
      ],
      "source": [
        "od.download(\n",
        "\t\"https://www.kaggle.com/datasets/andrewmvd/spotify-playlists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUBQu1M3wVml"
      },
      "outputs": [],
      "source": [
        "# Set the Spark master URL and other Spark settings\n",
        "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--master local[*] --executor-memory 4G --num-executors 4 pyspark-shell'\n",
        "conf = SparkConf(loadDefaults=True)\n",
        "conf.setMaster(\"local\").setAppName(\"sptifyApp\")\n",
        "sc = SparkContext(conf=conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SoVP3M8wbAM"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DuhicncxH0s"
      },
      "outputs": [],
      "source": [
        "spark.conf.set(\"spark.sql.pivotMaxValues\", 2200000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "fG49foAjxMjD",
        "outputId": "971e9b4a-7e33-4232-e7ed-5707f6ca80c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e5a7a572c80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://20866ca1a172:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>sptifyApp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Limpieza de datos"
      ],
      "metadata": {
        "id": "PiDmEFrkBFYb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr8ED4XBxerM",
        "outputId": "a0eebf7b-d2fc-4287-9b45-14c956448d03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(user_id='0dec62b08bd5ef26e79851d532f8ef82', artistname='Salif Keita', trackname='Bolon', playlistname='Dive Bar')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df = spark.read.option(\"header\", \"true\").csv(\"spotify-playlists//spotify_dataset.csv\")\n",
        "\n",
        "df.write.mode('overwrite').parquet('df.parquet')\n",
        "\n",
        "df = spark.read.parquet('df.parquet')\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "df = df.toDF(*[col.replace(' ', '').replace('\"', '') for col in df.columns])\n",
        "\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creando dimensiones separadas para playlists, artistas, canciones y usuarios, reconstruyendo la matriz de reproducciones con los indices de dichas dimensiones."
      ],
      "metadata": {
        "id": "XNVXXQgCBMh8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19w5BaphaqGx",
        "outputId": "4a50f234-1e1c-4881-da5f-2cd48df4ca35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(user_id='00055176fea33f6e027cd3302289378b', user_id_index=1), Row(user_id='0007f3dd09c91198371454c608d47f22', user_id_index=2), Row(user_id='000b0f32b5739f052b9d40fcc5c41079', user_id_index=3), Row(user_id='000c11a16c89aa4b14b328080f5954ee', user_id_index=4), Row(user_id='00123e0f544dee3ab006aa7f1e5725a7', user_id_index=5), Row(user_id='00139e9cb50fb309549e1561b476226d', user_id_index=6), Row(user_id='00152c870313100559aad7b097d9c1f5', user_id_index=7), Row(user_id='00154ec9dd1acd4ebfb521629dcb3948', user_id_index=8), Row(user_id='001599a07cb8ef5f114a9fcf4e0e2757', user_id_index=9), Row(user_id='0019363a0d57e94d39988c31eeb8d015', user_id_index=10)]\n",
            "[Row(artistname=' Dolce', artistname_index=1), Row(artistname=' OneVoice', artistname_index=2), Row(artistname='!!!', artistname_index=3), Row(artistname='!!! (Chk Chk Chk)', artistname_index=4), Row(artistname='!!! Chk Chik Chick', artistname_index=5), Row(artistname='!ATTENTION!', artistname_index=6), Row(artistname='!DELADAP', artistname_index=7), Row(artistname='!Dela Dap', artistname_index=8), Row(artistname='!DelaDap', artistname_index=9), Row(artistname='!Distain', artistname_index=10)]\n",
            "[Row(trackname=' \"Cachaito\" L√≥pez Y \"Guajiro\" Mirabal De Buena Vista Social Club Y Manuel \"Galb√°n\" Torralba\"', trackname_index=1), Row(trackname=' 15 Years of Tummy Touch Records in Dub', trackname_index=2), Row(trackname=' Alan Jackson', trackname_index=3), Row(trackname=' Ashley Tisdale', trackname_index=4), Row(trackname=' Ashley Tisdale & Lucas Grabeel\"', trackname_index=5), Row(trackname=' Babi Floyd\"', trackname_index=6), Row(trackname=' Babyface & Whitney Houston\"', trackname_index=7), Row(trackname=' Bert with The Whispering Orchestra\"', trackname_index=8), Row(trackname=' Bill Stepney\"', trackname_index=9), Row(trackname=' Bumblefoot', trackname_index=10)]\n",
            "[Row(playlistname=' ', playlistname_index=1), Row(playlistname='        waves', playlistname_index=2), Row(playlistname='  11', playlistname_index=3), Row(playlistname='  Frida', playlistname_index=4), Row(playlistname='  New tunes 05/11', playlistname_index=5), Row(playlistname=\"  You're the Worst\", playlistname_index=6), Row(playlistname='  joni mitchell       ', playlistname_index=7), Row(playlistname='  julia musica', playlistname_index=8), Row(playlistname=' !!', playlistname_index=9), Row(playlistname=' \"\"Appassionata\"\" - Allegro Assai \"\"', playlistname_index=10)]\n",
            "[Row(user_id_index=6511, artistname_index=15, trackname_index=1, playlistname_index=5707), Row(user_id_index=4852, artistname_index=49030, trackname_index=2, playlistname_index=70282), Row(user_id_index=4213, artistname_index=563, trackname_index=10, playlistname_index=577), Row(user_id_index=11018, artistname_index=54, trackname_index=12, playlistname_index=103765), Row(user_id_index=13724, artistname_index=603, trackname_index=28, playlistname_index=31610), Row(user_id_index=12560, artistname_index=344, trackname_index=40, playlistname_index=678), Row(user_id_index=10774, artistname_index=83640, trackname_index=54, playlistname_index=125146), Row(user_id_index=11031, artistname_index=191689, trackname_index=59, playlistname_index=27230), Row(user_id_index=13194, artistname_index=44720, trackname_index=72, playlistname_index=30108), Row(user_id_index=12626, artistname_index=172581, trackname_index=83, playlistname_index=153063)]\n"
          ]
        }
      ],
      "source": [
        "dims={}\n",
        "\n",
        "def df_dim(df, input_col):\n",
        "    windowSpec = Window.orderBy(input_col)\n",
        "    dims[input_col]=df.select(input_col).distinct().withColumn(f\"{input_col}_index\", fn.row_number().over(windowSpec))\n",
        "\n",
        "for col_name in df.columns:\n",
        "    df_dim(df,col_name)\n",
        "\n",
        "for dim in dims.values():\n",
        "    print(dim.head(10))\n",
        "\n",
        "newdf=df\n",
        "\n",
        "for i in range(0, len(df.columns)):\n",
        "    col_name = df.columns[i]\n",
        "    newdf=newdf.join(dims[col_name].withColumnRenamed(col_name, col_name+'_base'), fn.col(col_name)==fn.col(col_name+'_base')).drop(col_name).drop(col_name+'_base')\n",
        "\n",
        "print(newdf.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matriz de reporducciones seg√∫n el artista y normalizaci√≥n de los datos."
      ],
      "metadata": {
        "id": "rwyEmsfrBjjq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q4d3ht_cAhi"
      },
      "outputs": [],
      "source": [
        "counts_df = newdf.groupBy(\"user_id_index\", \"artistname_index\").agg(fn.count(\"*\").alias(\"reproductions\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TETF7Ha-cjqS",
        "outputId": "3473a263-956c-4949-b179-f82ee8851c3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(user_id_index=1, artistname_index=2499, reproductions=10, normalized_reproduction=0.0026905829596412557),\n",
              " Row(user_id_index=1, artistname_index=5070, reproductions=1, normalized_reproduction=0.0),\n",
              " Row(user_id_index=1, artistname_index=11192, reproductions=8, normalized_reproduction=0.0020926756352765323),\n",
              " Row(user_id_index=1, artistname_index=20733, reproductions=1, normalized_reproduction=0.0),\n",
              " Row(user_id_index=1, artistname_index=21137, reproductions=2, normalized_reproduction=0.00029895366218236175),\n",
              " Row(user_id_index=1, artistname_index=26209, reproductions=1, normalized_reproduction=0.0),\n",
              " Row(user_id_index=1, artistname_index=32666, reproductions=1, normalized_reproduction=0.0),\n",
              " Row(user_id_index=1, artistname_index=37366, reproductions=1, normalized_reproduction=0.0),\n",
              " Row(user_id_index=1, artistname_index=47981, reproductions=1, normalized_reproduction=0.0),\n",
              " Row(user_id_index=1, artistname_index=85883, reproductions=3, normalized_reproduction=0.0005979073243647235)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "max_reproduction = counts_df.agg({\"reproductions\": \"max\"}).collect()[0][0]\n",
        "min_reproduction = counts_df.agg({\"reproductions\": \"min\"}).collect()[0][0]\n",
        "\n",
        "normalized_pl_counts_df = counts_df.withColumn(\"normalized_reproduction\", (fn.col(\"reproductions\") - min_reproduction) / (max_reproduction - min_reproduction))\n",
        "normalized_pl_counts_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sistema de recomendaci√≥n de artistas"
      ],
      "metadata": {
        "id": "MAQ7HvgfAHab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuERLouodI2i",
        "outputId": "b86183c8-4c00-4e79-a232-b6c716654b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) = 0.12806876585364213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(user_id_index=1, recommendations=[Row(artistname_index=163412, rating=0.14453428983688354), Row(artistname_index=135095, rating=0.1390984207391739), Row(artistname_index=112985, rating=0.12903881072998047), Row(artistname_index=51082, rating=0.12721602618694305), Row(artistname_index=210588, rating=0.11653812974691391), Row(artistname_index=76809, rating=0.11591964215040207), Row(artistname_index=243033, rating=0.11045467108488083), Row(artistname_index=190699, rating=0.10443546622991562), Row(artistname_index=80113, rating=0.10440066456794739), Row(artistname_index=188137, rating=0.10249216109514236)]),\n",
              " Row(user_id_index=2, recommendations=[Row(artistname_index=112985, rating=0.07352685183286667), Row(artistname_index=177187, rating=0.0678005963563919), Row(artistname_index=89915, rating=0.06556925922632217), Row(artistname_index=51082, rating=0.061343226581811905), Row(artistname_index=101031, rating=0.05874035134911537), Row(artistname_index=85883, rating=0.05599679425358772), Row(artistname_index=149394, rating=0.05529361963272095), Row(artistname_index=285318, rating=0.05518519878387451), Row(artistname_index=192596, rating=0.05320969969034195), Row(artistname_index=76809, rating=0.050087280571460724)]),\n",
              " Row(user_id_index=3, recommendations=[Row(artistname_index=28600, rating=0.03151720017194748), Row(artistname_index=135095, rating=0.029445849359035492), Row(artistname_index=210588, rating=0.02941371500492096), Row(artistname_index=36605, rating=0.02625916339457035), Row(artistname_index=143141, rating=0.026171453297138214), Row(artistname_index=157985, rating=0.022629452869296074), Row(artistname_index=182584, rating=0.02119361236691475), Row(artistname_index=243033, rating=0.02117185853421688), Row(artistname_index=161852, rating=0.020899591967463493), Row(artistname_index=135786, rating=0.020758766680955887)]),\n",
              " Row(user_id_index=4, recommendations=[Row(artistname_index=51082, rating=0.52383953332901), Row(artistname_index=177187, rating=0.42677825689315796), Row(artistname_index=163412, rating=0.4013573229312897), Row(artistname_index=126554, rating=0.3844034671783447), Row(artistname_index=210588, rating=0.3806682229042053), Row(artistname_index=33914, rating=0.3711828887462616), Row(artistname_index=37366, rating=0.369830846786499), Row(artistname_index=89362, rating=0.3640071153640747), Row(artistname_index=135095, rating=0.36060085892677307), Row(artistname_index=28600, rating=0.3605588674545288)]),\n",
              " Row(user_id_index=5, recommendations=[Row(artistname_index=32856, rating=0.37905052304267883), Row(artistname_index=33914, rating=0.3185393512248993), Row(artistname_index=37256, rating=0.3129937946796417), Row(artistname_index=257149, rating=0.3121197819709778), Row(artistname_index=236202, rating=0.2958427667617798), Row(artistname_index=272308, rating=0.29385682940483093), Row(artistname_index=91263, rating=0.28971055150032043), Row(artistname_index=177187, rating=0.28685131669044495), Row(artistname_index=126554, rating=0.2851366400718689), Row(artistname_index=114674, rating=0.2759645879268646)]),\n",
              " Row(user_id_index=6, recommendations=[Row(artistname_index=59560, rating=0.18896646797657013), Row(artistname_index=51082, rating=0.15581980347633362), Row(artistname_index=177444, rating=0.12126320600509644), Row(artistname_index=252681, rating=0.11496201902627945), Row(artistname_index=169467, rating=0.10897465795278549), Row(artistname_index=17682, rating=0.1036267876625061), Row(artistname_index=204527, rating=0.10237512737512589), Row(artistname_index=203157, rating=0.097991444170475), Row(artistname_index=164255, rating=0.093171626329422), Row(artistname_index=258829, rating=0.08977662026882172)]),\n",
              " Row(user_id_index=8, recommendations=[Row(artistname_index=41327, rating=0.02571401558816433), Row(artistname_index=217000, rating=0.023402545601129532), Row(artistname_index=59560, rating=0.02294963225722313), Row(artistname_index=164895, rating=0.022863181307911873), Row(artistname_index=216611, rating=0.022754505276679993), Row(artistname_index=150028, rating=0.022741513326764107), Row(artistname_index=34153, rating=0.022240234538912773), Row(artistname_index=101546, rating=0.021977927535772324), Row(artistname_index=118249, rating=0.02197636105120182), Row(artistname_index=109823, rating=0.02195020206272602)]),\n",
              " Row(user_id_index=9, recommendations=[Row(artistname_index=278515, rating=0.0), Row(artistname_index=278500, rating=0.0), Row(artistname_index=278490, rating=0.0), Row(artistname_index=278485, rating=0.0), Row(artistname_index=278480, rating=0.0), Row(artistname_index=278470, rating=0.0), Row(artistname_index=278467, rating=0.0), Row(artistname_index=278465, rating=0.0), Row(artistname_index=278460, rating=0.0), Row(artistname_index=278457, rating=0.0)]),\n",
              " Row(user_id_index=10, recommendations=[Row(artistname_index=63521, rating=0.5376491546630859), Row(artistname_index=40206, rating=0.47811463475227356), Row(artistname_index=21058, rating=0.4766056537628174), Row(artistname_index=198927, rating=0.35602670907974243), Row(artistname_index=51082, rating=0.3513399064540863), Row(artistname_index=210588, rating=0.32461315393447876), Row(artistname_index=239684, rating=0.30947762727737427), Row(artistname_index=59560, rating=0.2855375409126282), Row(artistname_index=135095, rating=0.2700633108615875), Row(artistname_index=163412, rating=0.26283782720565796)]),\n",
              " Row(user_id_index=11, recommendations=[Row(artistname_index=210588, rating=0.6853534579277039), Row(artistname_index=135095, rating=0.635819673538208), Row(artistname_index=143141, rating=0.5721240639686584), Row(artistname_index=63521, rating=0.5053088665008545), Row(artistname_index=28600, rating=0.48504874110221863), Row(artistname_index=36605, rating=0.4843369126319885), Row(artistname_index=163412, rating=0.4682084619998932), Row(artistname_index=198927, rating=0.45737332105636597), Row(artistname_index=190699, rating=0.45325884222984314), Row(artistname_index=37366, rating=0.3966868817806244)])]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "(training, test) = normalized_pl_counts_df.randomSplit([0.8, 0.2])\n",
        "\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id_index\", itemCol=\"artistname_index\", ratingCol=\"normalized_reproduction\", coldStartStrategy=\"drop\",implicitPrefs=True)\n",
        "model = als.fit(training)\n",
        "\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"normalized_reproduction\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error (RMSE) = \" + str(rmse))\n",
        "\n",
        "#Top 10 recomendaciones por usuario\n",
        "userRecs = model.recommendForAllUsers(10)\n",
        "userRecs.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.write.mode('overwrite').parquet('test_data.parquet')\n",
        "\n",
        "test = spark.read.parquet('test_data.parquet')"
      ],
      "metadata": {
        "id": "lcXE-O-rXXlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_test = test.sample(withReplacement=False, fraction=0.05, seed=42)"
      ],
      "metadata": {
        "id": "gc9cKeqKedxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = sampled_test.select('user_id_index').distinct()\n",
        "user_ids.write.mode('overwrite').parquet('user_ids.parquet')\n",
        "\n",
        "user_ids = spark.read.parquet('user_ids.parquet')\n",
        "user_ids_list = user_ids.rdd.flatMap(lambda x: x).collect()"
      ],
      "metadata": {
        "id": "vkpDh2LyT9XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.functions import col, expr, lit\n",
        "from pyspark.sql import DataFrame\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Funci√≥n para recomendar los top K artistas para un usuario dado\n",
        "def recommend_top_k_artists(user_id_index, model, data, k=10):\n",
        "    user_subset = data.select('artistname_index').distinct()\n",
        "    user_subset = user_subset.withColumn('user_id_index', lit(user_id_index))\n",
        "    predictions = model.transform(user_subset)\n",
        "    top_k_artists = predictions.orderBy('prediction', ascending=False).limit(k)\n",
        "    top_k_artist_ids = [row['artistname_index'] for row in top_k_artists.collect()]\n",
        "    return top_k_artist_ids\n",
        "\n",
        "# Funci√≥n para calcular Precision@K\n",
        "def precision_at_k(recommended_items, relevant_items, k):\n",
        "    relevant_set = set(relevant_items)\n",
        "    recommended_set = set(recommended_items)\n",
        "    return len(recommended_set & relevant_set) / k\n",
        "\n",
        "# Funci√≥n para calcular MAP\n",
        "def average_precision(actual, predicted):\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "    for i, p in enumerate(predicted):\n",
        "        if p in actual and p not in predicted[:i]:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i + 1.0)\n",
        "    if not actual:\n",
        "        return 0.0\n",
        "    return score / min(len(actual), len(predicted))\n",
        "\n",
        "def mean_average_precision(actual_items, predicted_items):\n",
        "    return np.mean([average_precision(actual, predicted) for actual, predicted in zip(actual_items, predicted_items)])\n",
        "\n",
        "# Funciones para calcular NDCG\n",
        "def dcg_at_k(r, k):\n",
        "    r = np.asfarray(r)[:k]\n",
        "    if r.size:\n",
        "        return np.sum(np.divide(np.power(2, r) - 1, np.log2(np.arange(2, r.size + 2))))\n",
        "    return 0.0\n",
        "\n",
        "def ndcg_at_k(r, k):\n",
        "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
        "    if not idcg:\n",
        "        return 0.0\n",
        "    return dcg_at_k(r, k) / idcg\n",
        "\n",
        "def normalized_discounted_cumulative_gain(actual, predicted, k):\n",
        "    r = [1 if p in actual else 0 for p in predicted]\n",
        "    return ndcg_at_k(r, k)\n",
        "\n",
        "# Funci√≥n para evaluar el modelo\n",
        "def evaluate_model(test_data, model, k=10):\n",
        "    user_ids = test_data.select('user_id_index').distinct().rdd.flatMap(lambda x: x).collect()\n",
        "    avg_map = 0.0\n",
        "    avg_ndcg = 0.0\n",
        "    precision_scores = []\n",
        "    count = 0\n",
        "\n",
        "    for user_id in user_ids:\n",
        "        relevant_items = test_data.filter(col('user_id_index') == user_id).select('artistname_index').rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "        # Se ignoran usuarios que tengan pocos artistas (Arranque en fr√≠o)\n",
        "        if len(relevant_items) < 25:\n",
        "            continue\n",
        "\n",
        "        recommended_items = recommend_top_k_artists(user_id, model, test_data, k)\n",
        "\n",
        "        # Calcular Precision@K\n",
        "        precision = precision_at_k(recommended_items, relevant_items, k)\n",
        "        precision_scores.append(precision)\n",
        "\n",
        "        # Calcular MAP para el usuario actual\n",
        "        map_score = average_precision(relevant_items, recommended_items[:k])\n",
        "        avg_map += map_score\n",
        "\n",
        "        # Calcular NDCG para el usuario actual\n",
        "        ndcg_score = normalized_discounted_cumulative_gain(relevant_items, recommended_items, k)\n",
        "        avg_ndcg += ndcg_score\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    # Calcular promedio de MAP y NDCG para todos los usuarios\n",
        "    avg_precisionAtK = np.mean(precision_scores)\n",
        "    avg_map /= count\n",
        "    avg_ndcg /= count\n",
        "\n",
        "    return avg_precisionAtK, avg_map, avg_ndcg\n",
        "\n",
        "# Evaluar el modelo\n",
        "avg_precisionAtK, avg_map, avg_ndcg = evaluate_model(sampled_test, model, k=10)\n",
        "print(f\"Precision@10: {avg_precisionAtK:.4f}\")\n",
        "print(f\"Mean Average Precision (MAP)@10: {avg_map:.4f}\")\n",
        "print(f\"Normalized Discounted Cumulative Gain (NDCG)@10: {avg_ndcg:.4f}\")"
      ],
      "metadata": {
        "id": "r3LzuxYtxbN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 recomendaiones para un usuario"
      ],
      "metadata": {
        "id": "ZX1X1Rrv3xJa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4nP51nB0dVF",
        "outputId": "3c3b0c73-9547-461d-977a-539b599e11b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+---------------+--------------------+\n",
            "|artistname_index|     artistname|recommendation_score|\n",
            "+----------------+---------------+--------------------+\n",
            "|          157985|        Madonna|          0.02455879|\n",
            "|           63174|    David Bowie|         0.023608776|\n",
            "|          210588|        Rihanna|         0.022057204|\n",
            "|          169467|Michael Jackson|          0.02189978|\n",
            "|           28600|        Beyonc√©|         0.021125346|\n",
            "|          164255|    Marvin Gaye|         0.020584796|\n",
            "|          236202|  Stevie Wonder|         0.020487295|\n",
            "|          143141|      Lady Gaga|         0.018550886|\n",
            "|           36605| Britney Spears|         0.017046666|\n",
            "|           17755|Aretha Franklin|         0.016739469|\n",
            "+----------------+---------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_id_index = 5914  # Usuario de ejemplo\n",
        "\n",
        "playlist_df = userRecs.filter(fn.col(\"user_id_index\") == user_id_index).select(fn.explode(\"recommendations\").alias(\"recommendation\"))\n",
        "playlist_df = dims['artistname'].join(playlist_df.select(fn.col(\"recommendation.artistname_index\").alias(\"artistname_index\"), fn.col(\"recommendation.rating\").alias(\"recommendation_score\")),'artistname_index')\\\n",
        "              .orderBy(\"recommendation_score\", ascending=False)\n",
        "playlist_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los artistas que ya ha reproducido el usuario."
      ],
      "metadata": {
        "id": "4DgXscuZ3m4i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxwBZvOtptXH",
        "outputId": "6e2d8d53-da38-40e6-c52e-cb4253c0b613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------+\n",
            "|   artistname|reproductions|\n",
            "+-------------+-------------+\n",
            "|      Madonna|          290|\n",
            "|Talking Heads|          132|\n",
            "| Lana Del Rey|           12|\n",
            "|   Theme Park|            5|\n",
            "|  Hybrid Funk|            2|\n",
            "|     Smokeman|            1|\n",
            "+-------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "usr_reps = counts_df.filter(fn.col(\"user_id_index\") == user_id_index).distinct()\\\n",
        "    .join(dims['artistname'],'artistname_index').orderBy('reproductions', ascending=False).select('artistname','reproductions')\n",
        "\n",
        "usr_reps.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminando los artistas que el usuario ya ha reproducido\n",
        "\n",
        "print('Recomendaciones de artistas para el usuario:\\n')\n",
        "playlist_df.join(usr_reps, playlist_df[\"artistname\"] == usr_reps[\"artistname\"], \"left_anti\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuTRi7S77rdr",
        "outputId": "58e9400d-6e9c-49ff-c2e8-6012056cd43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recomendaciones de artistas para el usuario:\n",
            "\n",
            "+----------------+---------------+--------------------+\n",
            "|artistname_index|     artistname|recommendation_score|\n",
            "+----------------+---------------+--------------------+\n",
            "|           63174|    David Bowie|         0.023608776|\n",
            "|          210588|        Rihanna|         0.022057204|\n",
            "|          169467|Michael Jackson|          0.02189978|\n",
            "|           28600|        Beyonc√©|         0.021125346|\n",
            "|          164255|    Marvin Gaye|         0.020584796|\n",
            "|          236202|  Stevie Wonder|         0.020487295|\n",
            "|          143141|      Lady Gaga|         0.018550886|\n",
            "|           36605| Britney Spears|         0.017046666|\n",
            "|           17755|Aretha Franklin|         0.016739469|\n",
            "+----------------+---------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}